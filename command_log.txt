2025-08-24 10:57:53,123 - 2025-08-24 10:57:53 - Executing: luvia main --input_file "/home/alfredff/Toke/Maps for Alfred/Rigensgade bw_section.jpg" --blur_kernel "5,5" --blur_sigma "0" --block_size "15" --vthresh_C "3" --min_area "20" --max_area "2000" --min_aspect "0.1" --max_aspect "10.0" --min_vertices "6" --blur_kernel_size "5" --canny_thresh1 "50" --canny_thresh2 "150" --cc_min_area "20" --cc_max_area "2000" --contour_min_area "20" --contour_max_area "2000" --contour_min_vertices "5" --contour_max_vertices "0.001" --sigma "4" --separation_char "5" --hoofh_mode "cca" --min_area_segment "100" --dilation_kernel "90,10" --angle_tolerance "15" --filter_boxes "inside_box" --kernel_size "150,20" --iterations "1" --infer_mode "diverse_beam" --beam_width "3" --num_groups "3" --diversity_strength "0.5" --top_k "0" --top_p "0.9" --temperature "1.0" --k "1" --dictionary "False" --character "False"
2025-08-24 10:58:00,672 - 2025-08-24 10:57:53 - Error: usage: luvia main [-h] [-i INPUT] [-o OUTPUT]
                  [--clean_mode {OTSA,simple,False}] [--rotate_img ROTATE_IMG]
                  [-v] [--blur_kernel START END] [--blur_sigma BLUR_SIGMA]
                  [--block_size BLOCK_SIZE] [--vthresh_C VTHRESH_C]
                  [--min_area MIN_AREA] [--max_area MAX_AREA]
                  [--min_aspect MIN_ASPECT] [--max_aspect MAX_ASPECT]
                  [--min_vertices MIN_VERTICES]
                  [--blur_kernel_size BLUR_KERNEL_SIZE]
                  [--canny_thresh1 CANNY_THRESH1]
                  [--canny_thresh2 CANNY_THRESH2] [--cc_min_area CC_MIN_AREA]
                  [--cc_max_area CC_MAX_AREA]
                  [--contour_min_area CONTOUR_MIN_AREA]
                  [--contour_max_area CONTOUR_MAX_AREA]
                  [--contour_min_vertices CONTOUR_MIN_VERTICES]
                  [--contour_max_vertices CONTOUR_MAX_VERTICES]
                  [--sigma SIGMA] [--separation_char SEPARATION_CHAR]
                  [--hoofh_mode {cca,threshold}] [--filter_angle FILTER_ANGLE]
                  [--min_area_segment MIN_AREA_SEGMENT]
                  [--dilation_kernel START END]
                  [--angle_tolerance ANGLE_TOLERANCE]
                  [--filter_boxes FILTER_BOXES] [--kernel_size START END]
                  [--iterations ITERATIONS] [--weights WEIGHTS]
                  [--infer_mode INFER_MODE] [--length_norm LENGTH_NORM]
                  [--beam_width BEAM_WIDTH] [--num_groups NUM_GROUPS]
                  [--diversity_strength DIVERSITY_STRENGTH] [--top_k TOP_K]
                  [--top_p TOP_P] [--temperature TEMPERATURE] [--k K]
                  [--dictionary {False,match,POSmatch,characters}]
                  [--notransform_input] [--character CHARACTER]
luvia main: error: argument --blur_kernel: expected 2 arguments
2025-08-24 10:58:00,686 - 2025-08-24 10:58:00 - Executing: luvia main --input_file "/home/alfredff/Toke/Maps for Alfred/Rigensgade bw_section.jpg" --blur_kernel "5,5" --blur_sigma "0" --block_size "15" --vthresh_C "3" --min_area "20" --max_area "2000" --min_aspect "0.1" --max_aspect "10.0" --min_vertices "6" --blur_kernel_size "5" --canny_thresh1 "50" --canny_thresh2 "150" --cc_min_area "20" --cc_max_area "2000" --contour_min_area "20" --contour_max_area "2000" --contour_min_vertices "5" --contour_max_vertices "0.001" --sigma "4" --separation_char "5" --hoofh_mode "cca" --min_area_segment "100" --dilation_kernel "90,10" --angle_tolerance "15" --filter_boxes "inside_box" --kernel_size "150,20" --iterations "1" --infer_mode "diverse_beam" --beam_width "3" --num_groups "3" --diversity_strength "0.5" --top_k "0" --top_p "0.9" --temperature "1.0" --k "1" --dictionary "False" --character "False"
2025-08-24 10:58:08,484 - 2025-08-24 10:58:00 - Error: usage: luvia main [-h] [-i INPUT] [-o OUTPUT]
                  [--clean_mode {OTSA,simple,False}] [--rotate_img ROTATE_IMG]
                  [-v] [--blur_kernel START END] [--blur_sigma BLUR_SIGMA]
                  [--block_size BLOCK_SIZE] [--vthresh_C VTHRESH_C]
                  [--min_area MIN_AREA] [--max_area MAX_AREA]
                  [--min_aspect MIN_ASPECT] [--max_aspect MAX_ASPECT]
                  [--min_vertices MIN_VERTICES]
                  [--blur_kernel_size BLUR_KERNEL_SIZE]
                  [--canny_thresh1 CANNY_THRESH1]
                  [--canny_thresh2 CANNY_THRESH2] [--cc_min_area CC_MIN_AREA]
                  [--cc_max_area CC_MAX_AREA]
                  [--contour_min_area CONTOUR_MIN_AREA]
                  [--contour_max_area CONTOUR_MAX_AREA]
                  [--contour_min_vertices CONTOUR_MIN_VERTICES]
                  [--contour_max_vertices CONTOUR_MAX_VERTICES]
                  [--sigma SIGMA] [--separation_char SEPARATION_CHAR]
                  [--hoofh_mode {cca,threshold}] [--filter_angle FILTER_ANGLE]
                  [--min_area_segment MIN_AREA_SEGMENT]
                  [--dilation_kernel START END]
                  [--angle_tolerance ANGLE_TOLERANCE]
                  [--filter_boxes FILTER_BOXES] [--kernel_size START END]
                  [--iterations ITERATIONS] [--weights WEIGHTS]
                  [--infer_mode INFER_MODE] [--length_norm LENGTH_NORM]
                  [--beam_width BEAM_WIDTH] [--num_groups NUM_GROUPS]
                  [--diversity_strength DIVERSITY_STRENGTH] [--top_k TOP_K]
                  [--top_p TOP_P] [--temperature TEMPERATURE] [--k K]
                  [--dictionary {False,match,POSmatch,characters}]
                  [--notransform_input] [--character CHARACTER]
luvia main: error: argument --blur_kernel: expected 2 arguments
2025-08-24 10:58:08,494 - 2025-08-24 10:58:08 - Executing: luvia main --input_file "/home/alfredff/Toke/Maps for Alfred/Rigensgade bw_section.jpg" --blur_kernel "5,5" --blur_sigma "0" --block_size "15" --vthresh_C "3" --min_area "20" --max_area "2000" --min_aspect "0.1" --max_aspect "10.0" --min_vertices "6" --blur_kernel_size "5" --canny_thresh1 "50" --canny_thresh2 "150" --cc_min_area "20" --cc_max_area "2000" --contour_min_area "20" --contour_max_area "2000" --contour_min_vertices "5" --contour_max_vertices "0.001" --sigma "4" --separation_char "5" --hoofh_mode "cca" --min_area_segment "100" --dilation_kernel "90,10" --angle_tolerance "15" --filter_boxes "inside_box" --kernel_size "150,20" --iterations "1" --infer_mode "diverse_beam" --beam_width "3" --num_groups "3" --diversity_strength "0.5" --top_k "0" --top_p "0.9" --temperature "1.0" --k "1" --dictionary "False" --character "False"
2025-08-24 10:58:16,244 - 2025-08-24 10:58:08 - Error: usage: luvia main [-h] [-i INPUT] [-o OUTPUT]
                  [--clean_mode {OTSA,simple,False}] [--rotate_img ROTATE_IMG]
                  [-v] [--blur_kernel START END] [--blur_sigma BLUR_SIGMA]
                  [--block_size BLOCK_SIZE] [--vthresh_C VTHRESH_C]
                  [--min_area MIN_AREA] [--max_area MAX_AREA]
                  [--min_aspect MIN_ASPECT] [--max_aspect MAX_ASPECT]
                  [--min_vertices MIN_VERTICES]
                  [--blur_kernel_size BLUR_KERNEL_SIZE]
                  [--canny_thresh1 CANNY_THRESH1]
                  [--canny_thresh2 CANNY_THRESH2] [--cc_min_area CC_MIN_AREA]
                  [--cc_max_area CC_MAX_AREA]
                  [--contour_min_area CONTOUR_MIN_AREA]
                  [--contour_max_area CONTOUR_MAX_AREA]
                  [--contour_min_vertices CONTOUR_MIN_VERTICES]
                  [--contour_max_vertices CONTOUR_MAX_VERTICES]
                  [--sigma SIGMA] [--separation_char SEPARATION_CHAR]
                  [--hoofh_mode {cca,threshold}] [--filter_angle FILTER_ANGLE]
                  [--min_area_segment MIN_AREA_SEGMENT]
                  [--dilation_kernel START END]
                  [--angle_tolerance ANGLE_TOLERANCE]
                  [--filter_boxes FILTER_BOXES] [--kernel_size START END]
                  [--iterations ITERATIONS] [--weights WEIGHTS]
                  [--infer_mode INFER_MODE] [--length_norm LENGTH_NORM]
                  [--beam_width BEAM_WIDTH] [--num_groups NUM_GROUPS]
                  [--diversity_strength DIVERSITY_STRENGTH] [--top_k TOP_K]
                  [--top_p TOP_P] [--temperature TEMPERATURE] [--k K]
                  [--dictionary {False,match,POSmatch,characters}]
                  [--notransform_input] [--character CHARACTER]
luvia main: error: argument --blur_kernel: expected 2 arguments
2025-08-24 11:04:51,973 - 2025-08-24 11:04:51 - Executing: luvia main --input_file /home/alfredff/Toke/Maps for Alfred/Rigensgade bw_section.jpg --blur_kernel 5,5 --blur_sigma 0 --block_size 15 --vthresh_C 3 --min_area 20 --max_area 2000 --min_aspect 0.1 --max_aspect 10.0 --min_vertices 6 --blur_kernel_size 5 --canny_thresh1 50 --canny_thresh2 150 --cc_min_area 20 --cc_max_area 2000 --contour_min_area 20 --contour_max_area 2000 --contour_min_vertices 5 --contour_max_vertices 0.001 --sigma 4 --separation_char 5 --hoofh_mode cca --min_area_segment 100 --dilation_kernel 90,10 --angle_tolerance 15 --filter_boxes inside_box --kernel_size 150,20 --iterations 1 --infer_mode diverse_beam --beam_width 3 --num_groups 3 --diversity_strength 0.5 --top_k 0 --top_p 0.9 --temperature 1.0 --k 1 --dictionary False --character False
2025-08-24 11:05:00,723 - 2025-08-24 11:04:51 - Error: usage: luvia main [-h] [-i INPUT] [-o OUTPUT]
                  [--clean_mode {OTSA,simple,False}] [--rotate_img ROTATE_IMG]
                  [-v] [--blur_kernel START END] [--blur_sigma BLUR_SIGMA]
                  [--block_size BLOCK_SIZE] [--vthresh_C VTHRESH_C]
                  [--min_area MIN_AREA] [--max_area MAX_AREA]
                  [--min_aspect MIN_ASPECT] [--max_aspect MAX_ASPECT]
                  [--min_vertices MIN_VERTICES]
                  [--blur_kernel_size BLUR_KERNEL_SIZE]
                  [--canny_thresh1 CANNY_THRESH1]
                  [--canny_thresh2 CANNY_THRESH2] [--cc_min_area CC_MIN_AREA]
                  [--cc_max_area CC_MAX_AREA]
                  [--contour_min_area CONTOUR_MIN_AREA]
                  [--contour_max_area CONTOUR_MAX_AREA]
                  [--contour_min_vertices CONTOUR_MIN_VERTICES]
                  [--contour_max_vertices CONTOUR_MAX_VERTICES]
                  [--sigma SIGMA] [--separation_char SEPARATION_CHAR]
                  [--hoofh_mode {cca,threshold}] [--filter_angle FILTER_ANGLE]
                  [--min_area_segment MIN_AREA_SEGMENT]
                  [--dilation_kernel START END]
                  [--angle_tolerance ANGLE_TOLERANCE]
                  [--filter_boxes FILTER_BOXES] [--kernel_size START END]
                  [--iterations ITERATIONS] [--weights WEIGHTS]
                  [--infer_mode INFER_MODE] [--length_norm LENGTH_NORM]
                  [--beam_width BEAM_WIDTH] [--num_groups NUM_GROUPS]
                  [--diversity_strength DIVERSITY_STRENGTH] [--top_k TOP_K]
                  [--top_p TOP_P] [--temperature TEMPERATURE] [--k K]
                  [--dictionary {False,match,POSmatch,characters}]
                  [--notransform_input] [--character CHARACTER]
luvia main: error: argument --blur_kernel: expected 2 arguments
2025-08-24 11:05:18,590 - 2025-08-24 11:05:18 - Executing: luvia main --input_file /home/alfredff/Toke/Maps for Alfred/Rigensgade bw_section.jpg --blur_kernel 5, 5 --blur_sigma 0 --block_size 15 --vthresh_C 3 --min_area 20 --max_area 2000 --min_aspect 0.1 --max_aspect 10.0 --min_vertices 6 --blur_kernel_size 5 --canny_thresh1 50 --canny_thresh2 150 --cc_min_area 20 --cc_max_area 2000 --contour_min_area 20 --contour_max_area 2000 --contour_min_vertices 5 --contour_max_vertices 0.001 --sigma 4 --separation_char 5 --hoofh_mode cca --min_area_segment 100 --dilation_kernel 90,10 --angle_tolerance 15 --filter_boxes inside_box --kernel_size 150,20 --iterations 1 --infer_mode diverse_beam --beam_width 3 --num_groups 3 --diversity_strength 0.5 --top_k 0 --top_p 0.9 --temperature 1.0 --k 1 --dictionary False --character False
2025-08-24 11:05:26,264 - 2025-08-24 11:05:18 - Error: usage: luvia main [-h] [-i INPUT] [-o OUTPUT]
                  [--clean_mode {OTSA,simple,False}] [--rotate_img ROTATE_IMG]
                  [-v] [--blur_kernel START END] [--blur_sigma BLUR_SIGMA]
                  [--block_size BLOCK_SIZE] [--vthresh_C VTHRESH_C]
                  [--min_area MIN_AREA] [--max_area MAX_AREA]
                  [--min_aspect MIN_ASPECT] [--max_aspect MAX_ASPECT]
                  [--min_vertices MIN_VERTICES]
                  [--blur_kernel_size BLUR_KERNEL_SIZE]
                  [--canny_thresh1 CANNY_THRESH1]
                  [--canny_thresh2 CANNY_THRESH2] [--cc_min_area CC_MIN_AREA]
                  [--cc_max_area CC_MAX_AREA]
                  [--contour_min_area CONTOUR_MIN_AREA]
                  [--contour_max_area CONTOUR_MAX_AREA]
                  [--contour_min_vertices CONTOUR_MIN_VERTICES]
                  [--contour_max_vertices CONTOUR_MAX_VERTICES]
                  [--sigma SIGMA] [--separation_char SEPARATION_CHAR]
                  [--hoofh_mode {cca,threshold}] [--filter_angle FILTER_ANGLE]
                  [--min_area_segment MIN_AREA_SEGMENT]
                  [--dilation_kernel START END]
                  [--angle_tolerance ANGLE_TOLERANCE]
                  [--filter_boxes FILTER_BOXES] [--kernel_size START END]
                  [--iterations ITERATIONS] [--weights WEIGHTS]
                  [--infer_mode INFER_MODE] [--length_norm LENGTH_NORM]
                  [--beam_width BEAM_WIDTH] [--num_groups NUM_GROUPS]
                  [--diversity_strength DIVERSITY_STRENGTH] [--top_k TOP_K]
                  [--top_p TOP_P] [--temperature TEMPERATURE] [--k K]
                  [--dictionary {False,match,POSmatch,characters}]
                  [--notransform_input] [--character CHARACTER]
luvia main: error: argument --blur_kernel: invalid int value: '5,'
2025-08-24 11:05:40,691 - 2025-08-24 11:05:40 - Executing: luvia main --input_file /home/alfredff/Toke/Maps for Alfred/Rigensgade bw_section.jpg --blur_kernel 5 5 --blur_sigma 0 --block_size 15 --vthresh_C 3 --min_area 20 --max_area 2000 --min_aspect 0.1 --max_aspect 10.0 --min_vertices 6 --blur_kernel_size 5 --canny_thresh1 50 --canny_thresh2 150 --cc_min_area 20 --cc_max_area 2000 --contour_min_area 20 --contour_max_area 2000 --contour_min_vertices 5 --contour_max_vertices 0.001 --sigma 4 --separation_char 5 --hoofh_mode cca --min_area_segment 100 --dilation_kernel 90,10 --angle_tolerance 15 --filter_boxes inside_box --kernel_size 150,20 --iterations 1 --infer_mode diverse_beam --beam_width 3 --num_groups 3 --diversity_strength 0.5 --top_k 0 --top_p 0.9 --temperature 1.0 --k 1 --dictionary False --character False
2025-08-24 11:05:48,283 - 2025-08-24 11:05:40 - Error: usage: luvia main [-h] [-i INPUT] [-o OUTPUT]
                  [--clean_mode {OTSA,simple,False}] [--rotate_img ROTATE_IMG]
                  [-v] [--blur_kernel START END] [--blur_sigma BLUR_SIGMA]
                  [--block_size BLOCK_SIZE] [--vthresh_C VTHRESH_C]
                  [--min_area MIN_AREA] [--max_area MAX_AREA]
                  [--min_aspect MIN_ASPECT] [--max_aspect MAX_ASPECT]
                  [--min_vertices MIN_VERTICES]
                  [--blur_kernel_size BLUR_KERNEL_SIZE]
                  [--canny_thresh1 CANNY_THRESH1]
                  [--canny_thresh2 CANNY_THRESH2] [--cc_min_area CC_MIN_AREA]
                  [--cc_max_area CC_MAX_AREA]
                  [--contour_min_area CONTOUR_MIN_AREA]
                  [--contour_max_area CONTOUR_MAX_AREA]
                  [--contour_min_vertices CONTOUR_MIN_VERTICES]
                  [--contour_max_vertices CONTOUR_MAX_VERTICES]
                  [--sigma SIGMA] [--separation_char SEPARATION_CHAR]
                  [--hoofh_mode {cca,threshold}] [--filter_angle FILTER_ANGLE]
                  [--min_area_segment MIN_AREA_SEGMENT]
                  [--dilation_kernel START END]
                  [--angle_tolerance ANGLE_TOLERANCE]
                  [--filter_boxes FILTER_BOXES] [--kernel_size START END]
                  [--iterations ITERATIONS] [--weights WEIGHTS]
                  [--infer_mode INFER_MODE] [--length_norm LENGTH_NORM]
                  [--beam_width BEAM_WIDTH] [--num_groups NUM_GROUPS]
                  [--diversity_strength DIVERSITY_STRENGTH] [--top_k TOP_K]
                  [--top_p TOP_P] [--temperature TEMPERATURE] [--k K]
                  [--dictionary {False,match,POSmatch,characters}]
                  [--notransform_input] [--character CHARACTER]
luvia main: error: argument --dilation_kernel: expected 2 arguments
2025-08-24 11:06:10,546 - 2025-08-24 11:06:10 - Executing: luvia main --input_file /home/alfredff/Toke/Maps for Alfred/Rigensgade bw_section.jpg --blur_kernel 5 5 --blur_sigma 0 --block_size 15 --vthresh_C 3 --min_area 20 --max_area 2000 --min_aspect 0.1 --max_aspect 10.0 --min_vertices 6 --blur_kernel_size 5 --canny_thresh1 50 --canny_thresh2 150 --cc_min_area 20 --cc_max_area 2000 --contour_min_area 20 --contour_max_area 2000 --contour_min_vertices 5 --contour_max_vertices 0.001 --sigma 4 --separation_char 5 --hoofh_mode cca --min_area_segment 100 --dilation_kernel 90 10 --angle_tolerance 15 --filter_boxes inside_box --kernel_size 150,20 --iterations 1 --infer_mode diverse_beam --beam_width 3 --num_groups 3 --diversity_strength 0.5 --top_k 0 --top_p 0.9 --temperature 1.0 --k 1 --dictionary False --character False
2025-08-24 11:06:18,305 - 2025-08-24 11:06:10 - Error: usage: luvia main [-h] [-i INPUT] [-o OUTPUT]
                  [--clean_mode {OTSA,simple,False}] [--rotate_img ROTATE_IMG]
                  [-v] [--blur_kernel START END] [--blur_sigma BLUR_SIGMA]
                  [--block_size BLOCK_SIZE] [--vthresh_C VTHRESH_C]
                  [--min_area MIN_AREA] [--max_area MAX_AREA]
                  [--min_aspect MIN_ASPECT] [--max_aspect MAX_ASPECT]
                  [--min_vertices MIN_VERTICES]
                  [--blur_kernel_size BLUR_KERNEL_SIZE]
                  [--canny_thresh1 CANNY_THRESH1]
                  [--canny_thresh2 CANNY_THRESH2] [--cc_min_area CC_MIN_AREA]
                  [--cc_max_area CC_MAX_AREA]
                  [--contour_min_area CONTOUR_MIN_AREA]
                  [--contour_max_area CONTOUR_MAX_AREA]
                  [--contour_min_vertices CONTOUR_MIN_VERTICES]
                  [--contour_max_vertices CONTOUR_MAX_VERTICES]
                  [--sigma SIGMA] [--separation_char SEPARATION_CHAR]
                  [--hoofh_mode {cca,threshold}] [--filter_angle FILTER_ANGLE]
                  [--min_area_segment MIN_AREA_SEGMENT]
                  [--dilation_kernel START END]
                  [--angle_tolerance ANGLE_TOLERANCE]
                  [--filter_boxes FILTER_BOXES] [--kernel_size START END]
                  [--iterations ITERATIONS] [--weights WEIGHTS]
                  [--infer_mode INFER_MODE] [--length_norm LENGTH_NORM]
                  [--beam_width BEAM_WIDTH] [--num_groups NUM_GROUPS]
                  [--diversity_strength DIVERSITY_STRENGTH] [--top_k TOP_K]
                  [--top_p TOP_P] [--temperature TEMPERATURE] [--k K]
                  [--dictionary {False,match,POSmatch,characters}]
                  [--notransform_input] [--character CHARACTER]
luvia main: error: argument --kernel_size: expected 2 arguments
2025-08-24 11:06:32,304 - 2025-08-24 11:06:32 - Executing: luvia main --input_file /home/alfredff/Toke/Maps for Alfred/Rigensgade bw_section.jpg --blur_kernel 5 5 --blur_sigma 0 --block_size 15 --vthresh_C 3 --min_area 20 --max_area 2000 --min_aspect 0.1 --max_aspect 10.0 --min_vertices 6 --blur_kernel_size 5 --canny_thresh1 50 --canny_thresh2 150 --cc_min_area 20 --cc_max_area 2000 --contour_min_area 20 --contour_max_area 2000 --contour_min_vertices 5 --contour_max_vertices 0.001 --sigma 4 --separation_char 5 --hoofh_mode cca --min_area_segment 100 --dilation_kernel 90 10 --angle_tolerance 15 --filter_boxes inside_box --kernel_size 150 20 --iterations 1 --infer_mode diverse_beam --beam_width 3 --num_groups 3 --diversity_strength 0.5 --top_k 0 --top_p 0.9 --temperature 1.0 --k 1 --dictionary False --character False
2025-08-24 11:06:39,882 - 2025-08-24 11:06:32 - Error: usage: luvia main [-h] [-i INPUT] [-o OUTPUT]
                  [--clean_mode {OTSA,simple,False}] [--rotate_img ROTATE_IMG]
                  [-v] [--blur_kernel START END] [--blur_sigma BLUR_SIGMA]
                  [--block_size BLOCK_SIZE] [--vthresh_C VTHRESH_C]
                  [--min_area MIN_AREA] [--max_area MAX_AREA]
                  [--min_aspect MIN_ASPECT] [--max_aspect MAX_ASPECT]
                  [--min_vertices MIN_VERTICES]
                  [--blur_kernel_size BLUR_KERNEL_SIZE]
                  [--canny_thresh1 CANNY_THRESH1]
                  [--canny_thresh2 CANNY_THRESH2] [--cc_min_area CC_MIN_AREA]
                  [--cc_max_area CC_MAX_AREA]
                  [--contour_min_area CONTOUR_MIN_AREA]
                  [--contour_max_area CONTOUR_MAX_AREA]
                  [--contour_min_vertices CONTOUR_MIN_VERTICES]
                  [--contour_max_vertices CONTOUR_MAX_VERTICES]
                  [--sigma SIGMA] [--separation_char SEPARATION_CHAR]
                  [--hoofh_mode {cca,threshold}] [--filter_angle FILTER_ANGLE]
                  [--min_area_segment MIN_AREA_SEGMENT]
                  [--dilation_kernel START END]
                  [--angle_tolerance ANGLE_TOLERANCE]
                  [--filter_boxes FILTER_BOXES] [--kernel_size START END]
                  [--iterations ITERATIONS] [--weights WEIGHTS]
                  [--infer_mode INFER_MODE] [--length_norm LENGTH_NORM]
                  [--beam_width BEAM_WIDTH] [--num_groups NUM_GROUPS]
                  [--diversity_strength DIVERSITY_STRENGTH] [--top_k TOP_K]
                  [--top_p TOP_P] [--temperature TEMPERATURE] [--k K]
                  [--dictionary {False,match,POSmatch,characters}]
                  [--notransform_input] [--character CHARACTER]
luvia main: error: argument --dictionary: invalid choice: 'False' (choose from False, 'match', 'POSmatch', 'characters')
2025-08-24 11:07:08,635 - 2025-08-24 11:07:08 - Executing: luvia main --input_file /home/alfredff/Toke/Maps for Alfred/Rigensgade bw_section.jpg --blur_kernel 5 5 --blur_sigma 0 --block_size 15 --vthresh_C 3 --min_area 20 --max_area 2000 --min_aspect 0.1 --max_aspect 10.0 --min_vertices 6 --blur_kernel_size 5 --canny_thresh1 50 --canny_thresh2 150 --cc_min_area 20 --cc_max_area 2000 --contour_min_area 20 --contour_max_area 2000 --contour_min_vertices 5 --contour_max_vertices 0.001 --sigma 4 --separation_char 5 --hoofh_mode cca --min_area_segment 100 --dilation_kernel 90 10 --angle_tolerance 15 --filter_boxes inside_box --kernel_size 150 20 --iterations 1 --infer_mode diverse_beam --beam_width 3 --num_groups 3 --diversity_strength 0.5 --top_k 0 --top_p 0.9 --temperature 1.0 --k 1 --dictionary characters --character random
2025-08-24 11:07:16,298 - 2025-08-24 11:07:08 - Error: usage: luvia [-h] {main,clean,tongue,hoof,straw,spiral} ...
luvia: error: unrecognized arguments: --input_file /home/alfredff/Toke/Maps for Alfred/Rigensgade bw_section.jpg
2025-08-24 11:09:19,368 - 2025-08-24 11:09:19 - Executing: luvia main --input /home/alfredff/Toke/Maps for Alfred/Rigensgade bw_section.jpg --blur_kernel 5,5 --blur_sigma 0 --block_size 15 --vthresh_C 3 --min_area 20 --max_area 2000 --min_aspect 0.1 --max_aspect 10.0 --min_vertices 6 --blur_kernel_size 5 --canny_thresh1 50 --canny_thresh2 150 --cc_min_area 20 --cc_max_area 2000 --contour_min_area 20 --contour_max_area 2000 --contour_min_vertices 5 --contour_max_vertices 0.001 --sigma 4 --separation_char 5 --hoofh_mode cca --min_area_segment 100 --dilation_kernel 90,10 --angle_tolerance 15 --filter_boxes inside_box --kernel_size 150,20 --iterations 1 --infer_mode diverse_beam --beam_width 3 --num_groups 3 --diversity_strength 0.5 --top_k 0 --top_p 0.9 --temperature 1.0 --k 1 --dictionary False --character False
2025-08-24 11:09:26,989 - 2025-08-24 11:09:19 - Error: usage: luvia main [-h] [-i INPUT] [-o OUTPUT]
                  [--clean_mode {OTSA,simple,False}] [--rotate_img ROTATE_IMG]
                  [-v] [--blur_kernel START END] [--blur_sigma BLUR_SIGMA]
                  [--block_size BLOCK_SIZE] [--vthresh_C VTHRESH_C]
                  [--min_area MIN_AREA] [--max_area MAX_AREA]
                  [--min_aspect MIN_ASPECT] [--max_aspect MAX_ASPECT]
                  [--min_vertices MIN_VERTICES]
                  [--blur_kernel_size BLUR_KERNEL_SIZE]
                  [--canny_thresh1 CANNY_THRESH1]
                  [--canny_thresh2 CANNY_THRESH2] [--cc_min_area CC_MIN_AREA]
                  [--cc_max_area CC_MAX_AREA]
                  [--contour_min_area CONTOUR_MIN_AREA]
                  [--contour_max_area CONTOUR_MAX_AREA]
                  [--contour_min_vertices CONTOUR_MIN_VERTICES]
                  [--contour_max_vertices CONTOUR_MAX_VERTICES]
                  [--sigma SIGMA] [--separation_char SEPARATION_CHAR]
                  [--hoofh_mode {cca,threshold}] [--filter_angle FILTER_ANGLE]
                  [--min_area_segment MIN_AREA_SEGMENT]
                  [--dilation_kernel START END]
                  [--angle_tolerance ANGLE_TOLERANCE]
                  [--filter_boxes FILTER_BOXES] [--kernel_size START END]
                  [--iterations ITERATIONS] [--weights WEIGHTS]
                  [--infer_mode INFER_MODE] [--length_norm LENGTH_NORM]
                  [--beam_width BEAM_WIDTH] [--num_groups NUM_GROUPS]
                  [--diversity_strength DIVERSITY_STRENGTH] [--top_k TOP_K]
                  [--top_p TOP_P] [--temperature TEMPERATURE] [--k K]
                  [--dictionary {False,match,POSmatch,characters}]
                  [--notransform_input] [--character CHARACTER]
luvia main: error: argument --blur_kernel: expected 2 arguments
2025-08-24 17:03:09,188 - 2025-08-24 17:03:09 - Executing: luvia main --input /home/alfredff/Toke/Maps for Alfred/Rigensgade bw_section.jpg --blur_kernel 5,5 --blur_sigma 0 --block_size 15 --vthresh_C 3 --min_area 20 --max_area 2000 --min_aspect 0.1 --max_aspect 10.0 --min_vertices 6 --blur_kernel_size 5 --canny_thresh1 50 --canny_thresh2 150 --cc_min_area 20 --cc_max_area 2000 --contour_min_area 20 --contour_max_area 2000 --contour_min_vertices 5 --contour_max_vertices 0.001 --sigma 4 --separation_char 5 --hoofh_mode cca --min_area_segment 100 --dilation_kernel 90,10 --angle_tolerance 15 --filter_boxes inside_box --kernel_size 150,20 --iterations 1 --infer_mode diverse_beam --beam_width 3 --num_groups 3 --diversity_strength 0.5 --top_k 0 --top_p 0.9 --temperature 1.0 --k 1 --dictionary False --character False
2025-08-24 17:03:18,967 - 2025-08-24 17:03:09 - Error: usage: luvia main [-h] [-i INPUT] [-o OUTPUT]
                  [--clean_mode {OTSA,simple,False}] [--rotate_img ROTATE_IMG]
                  [-v] [--blur_kernel BLUR_KERNEL] [--blur_sigma BLUR_SIGMA]
                  [--block_size BLOCK_SIZE] [--vthresh_C VTHRESH_C]
                  [--min_area MIN_AREA] [--max_area MAX_AREA]
                  [--min_aspect MIN_ASPECT] [--max_aspect MAX_ASPECT]
                  [--min_vertices MIN_VERTICES]
                  [--blur_kernel_size BLUR_KERNEL_SIZE]
                  [--canny_thresh1 CANNY_THRESH1]
                  [--canny_thresh2 CANNY_THRESH2] [--cc_min_area CC_MIN_AREA]
                  [--cc_max_area CC_MAX_AREA]
                  [--contour_min_area CONTOUR_MIN_AREA]
                  [--contour_max_area CONTOUR_MAX_AREA]
                  [--contour_min_vertices CONTOUR_MIN_VERTICES]
                  [--contour_max_vertices CONTOUR_MAX_VERTICES]
                  [--sigma SIGMA] [--separation_char SEPARATION_CHAR]
                  [--hoofh_mode {cca,threshold}] [--filter_angle FILTER_ANGLE]
                  [--min_area_segment MIN_AREA_SEGMENT]
                  [--dilation_kernel START END]
                  [--angle_tolerance ANGLE_TOLERANCE]
                  [--filter_boxes FILTER_BOXES] [--kernel_size START END]
                  [--iterations ITERATIONS] [--weights WEIGHTS]
                  [--infer_mode INFER_MODE] [--length_norm LENGTH_NORM]
                  [--beam_width BEAM_WIDTH] [--num_groups NUM_GROUPS]
                  [--diversity_strength DIVERSITY_STRENGTH] [--top_k TOP_K]
                  [--top_p TOP_P] [--temperature TEMPERATURE] [--k K]
                  [--dictionary {False,match,POSmatch,characters}]
                  [--notransform_input] [--character CHARACTER]
luvia main: error: argument --dilation_kernel: expected 2 arguments
2025-08-24 17:04:08,869 - 2025-08-24 17:04:08 - Executing: luvia main --input /home/alfredff/Toke/Maps for Alfred/Rigensgade bw_section.jpg --blur_kernel 5,5 --blur_sigma 0 --block_size 15 --vthresh_C 3 --min_area 20 --max_area 2000 --min_aspect 0.1 --max_aspect 10.0 --min_vertices 6 --blur_kernel_size 5 --canny_thresh1 50 --canny_thresh2 150 --cc_min_area 20 --cc_max_area 2000 --contour_min_area 20 --contour_max_area 2000 --contour_min_vertices 5 --contour_max_vertices 0.001 --sigma 4 --separation_char 5 --hoofh_mode cca --min_area_segment 100 --dilation_kernel 90,10 --angle_tolerance 15 --filter_boxes inside_box --kernel_size 150,20 --iterations 1 --infer_mode diverse_beam --beam_width 3 --num_groups 3 --diversity_strength 0.5 --top_k 0 --top_p 0.9 --temperature 1.0 --k 1 --dictionary False --character False
2025-08-24 17:04:16,104 - 2025-08-24 17:04:08 - Error: usage: luvia main [-h] [-i INPUT] [-o OUTPUT]
                  [--clean_mode {OTSA,simple,False}] [--rotate_img ROTATE_IMG]
                  [-v] [--blur_kernel BLUR_KERNEL] [--blur_sigma BLUR_SIGMA]
                  [--block_size BLOCK_SIZE] [--vthresh_C VTHRESH_C]
                  [--min_area MIN_AREA] [--max_area MAX_AREA]
                  [--min_aspect MIN_ASPECT] [--max_aspect MAX_ASPECT]
                  [--min_vertices MIN_VERTICES]
                  [--blur_kernel_size BLUR_KERNEL_SIZE]
                  [--canny_thresh1 CANNY_THRESH1]
                  [--canny_thresh2 CANNY_THRESH2] [--cc_min_area CC_MIN_AREA]
                  [--cc_max_area CC_MAX_AREA]
                  [--contour_min_area CONTOUR_MIN_AREA]
                  [--contour_max_area CONTOUR_MAX_AREA]
                  [--contour_min_vertices CONTOUR_MIN_VERTICES]
                  [--contour_max_vertices CONTOUR_MAX_VERTICES]
                  [--sigma SIGMA] [--separation_char SEPARATION_CHAR]
                  [--hoofh_mode {cca,threshold}] [--filter_angle FILTER_ANGLE]
                  [--min_area_segment MIN_AREA_SEGMENT]
                  [--dilation_kernel DILATION_KERNEL]
                  [--angle_tolerance ANGLE_TOLERANCE]
                  [--filter_boxes FILTER_BOXES] [--kernel_size KERNEL_SIZE]
                  [--iterations ITERATIONS] [--weights WEIGHTS]
                  [--infer_mode INFER_MODE] [--length_norm LENGTH_NORM]
                  [--beam_width BEAM_WIDTH] [--num_groups NUM_GROUPS]
                  [--diversity_strength DIVERSITY_STRENGTH] [--top_k TOP_K]
                  [--top_p TOP_P] [--temperature TEMPERATURE] [--k K]
                  [--dictionary {False,match,POSmatch,characters}]
                  [--notransform_input] [--character CHARACTER]
luvia main: error: argument --dictionary: invalid choice: 'False' (choose from False, 'match', 'POSmatch', 'characters')
2025-08-24 17:04:41,171 - 2025-08-24 17:04:41 - Executing: luvia main --input /home/alfredff/Toke/Maps for Alfred/Rigensgade bw_section.jpg --blur_kernel 5,5 --blur_sigma 0 --block_size 15 --vthresh_C 3 --min_area 20 --max_area 2000 --min_aspect 0.1 --max_aspect 10.0 --min_vertices 6 --blur_kernel_size 5 --canny_thresh1 50 --canny_thresh2 150 --cc_min_area 20 --cc_max_area 2000 --contour_min_area 20 --contour_max_area 2000 --contour_min_vertices 5 --contour_max_vertices 0.001 --sigma 4 --separation_char 5 --hoofh_mode cca --min_area_segment 100 --dilation_kernel 90,10 --angle_tolerance 15 --filter_boxes inside_box --kernel_size 150,20 --iterations 1 --infer_mode diverse_beam --beam_width 3 --num_groups 3 --diversity_strength 0.5 --top_k 0 --top_p 0.9 --temperature 1.0 --k 1 --dictionary characters --character random
2025-08-24 17:04:48,480 - 2025-08-24 17:04:41 - Error: usage: luvia [-h] {main,clean,tongue,hoof,straw,spiral} ...
luvia: error: unrecognized arguments: for Alfred/Rigensgade bw_section.jpg
2025-08-24 17:06:29,279 - 2025-08-24 17:06:29 - Executing: luvia main --input '/home/alfredff/Toke/Maps for Alfred/Rigensgade bw_section.jpg' --blur_kernel 5,5 --blur_sigma 0 --block_size 15 --vthresh_C 3 --min_area 20 --max_area 2000 --min_aspect 0.1 --max_aspect 10.0 --min_vertices 6 --blur_kernel_size 5 --canny_thresh1 50 --canny_thresh2 150 --cc_min_area 20 --cc_max_area 2000 --contour_min_area 20 --contour_max_area 2000 --contour_min_vertices 5 --contour_max_vertices 0.001 --sigma 4 --separation_char 5 --hoofh_mode cca --min_area_segment 100 --dilation_kernel 90,10 --angle_tolerance 15 --filter_boxes inside_box --kernel_size 150,20 --iterations 1 --infer_mode diverse_beam --beam_width 3 --num_groups 3 --diversity_strength 0.5 --top_k 0 --top_p 0.9 --temperature 1.0 --k 1 --dictionary False --character False
2025-08-24 17:06:36,455 - 2025-08-24 17:06:29 - Error: usage: luvia main [-h] [-i INPUT] [-o OUTPUT]
                  [--clean_mode {OTSA,simple,False}] [--rotate_img ROTATE_IMG]
                  [-v] [--blur_kernel BLUR_KERNEL] [--blur_sigma BLUR_SIGMA]
                  [--block_size BLOCK_SIZE] [--vthresh_C VTHRESH_C]
                  [--min_area MIN_AREA] [--max_area MAX_AREA]
                  [--min_aspect MIN_ASPECT] [--max_aspect MAX_ASPECT]
                  [--min_vertices MIN_VERTICES]
                  [--blur_kernel_size BLUR_KERNEL_SIZE]
                  [--canny_thresh1 CANNY_THRESH1]
                  [--canny_thresh2 CANNY_THRESH2] [--cc_min_area CC_MIN_AREA]
                  [--cc_max_area CC_MAX_AREA]
                  [--contour_min_area CONTOUR_MIN_AREA]
                  [--contour_max_area CONTOUR_MAX_AREA]
                  [--contour_min_vertices CONTOUR_MIN_VERTICES]
                  [--contour_max_vertices CONTOUR_MAX_VERTICES]
                  [--sigma SIGMA] [--separation_char SEPARATION_CHAR]
                  [--hoofh_mode {cca,threshold}] [--filter_angle FILTER_ANGLE]
                  [--min_area_segment MIN_AREA_SEGMENT]
                  [--dilation_kernel DILATION_KERNEL]
                  [--angle_tolerance ANGLE_TOLERANCE]
                  [--filter_boxes FILTER_BOXES] [--kernel_size KERNEL_SIZE]
                  [--iterations ITERATIONS] [--weights WEIGHTS]
                  [--infer_mode INFER_MODE] [--length_norm LENGTH_NORM]
                  [--beam_width BEAM_WIDTH] [--num_groups NUM_GROUPS]
                  [--diversity_strength DIVERSITY_STRENGTH] [--top_k TOP_K]
                  [--top_p TOP_P] [--temperature TEMPERATURE] [--k K]
                  [--dictionary {False,match,POSmatch,characters}]
                  [--notransform_input] [--character CHARACTER]
luvia main: error: argument --dictionary: invalid choice: 'False' (choose from False, 'match', 'POSmatch', 'characters')
2025-08-24 17:06:36,471 - 2025-08-24 17:06:36 - Executing: luvia main --input '/home/alfredff/Toke/Maps for Alfred/Rigensgade bw_section.jpg' --blur_kernel 5,5 --blur_sigma 0 --block_size 15 --vthresh_C 3 --min_area 20 --max_area 2000 --min_aspect 0.1 --max_aspect 10.0 --min_vertices 6 --blur_kernel_size 5 --canny_thresh1 50 --canny_thresh2 150 --cc_min_area 20 --cc_max_area 2000 --contour_min_area 20 --contour_max_area 2000 --contour_min_vertices 5 --contour_max_vertices 0.001 --sigma 4 --separation_char 5 --hoofh_mode cca --min_area_segment 100 --dilation_kernel 90,10 --angle_tolerance 15 --filter_boxes inside_box --kernel_size 150,20 --iterations 1 --infer_mode diverse_beam --beam_width 3 --num_groups 3 --diversity_strength 0.5 --top_k 0 --top_p 0.9 --temperature 1.0 --k 1 --dictionary False --character False
2025-08-24 17:06:43,706 - 2025-08-24 17:06:36 - Error: usage: luvia main [-h] [-i INPUT] [-o OUTPUT]
                  [--clean_mode {OTSA,simple,False}] [--rotate_img ROTATE_IMG]
                  [-v] [--blur_kernel BLUR_KERNEL] [--blur_sigma BLUR_SIGMA]
                  [--block_size BLOCK_SIZE] [--vthresh_C VTHRESH_C]
                  [--min_area MIN_AREA] [--max_area MAX_AREA]
                  [--min_aspect MIN_ASPECT] [--max_aspect MAX_ASPECT]
                  [--min_vertices MIN_VERTICES]
                  [--blur_kernel_size BLUR_KERNEL_SIZE]
                  [--canny_thresh1 CANNY_THRESH1]
                  [--canny_thresh2 CANNY_THRESH2] [--cc_min_area CC_MIN_AREA]
                  [--cc_max_area CC_MAX_AREA]
                  [--contour_min_area CONTOUR_MIN_AREA]
                  [--contour_max_area CONTOUR_MAX_AREA]
                  [--contour_min_vertices CONTOUR_MIN_VERTICES]
                  [--contour_max_vertices CONTOUR_MAX_VERTICES]
                  [--sigma SIGMA] [--separation_char SEPARATION_CHAR]
                  [--hoofh_mode {cca,threshold}] [--filter_angle FILTER_ANGLE]
                  [--min_area_segment MIN_AREA_SEGMENT]
                  [--dilation_kernel DILATION_KERNEL]
                  [--angle_tolerance ANGLE_TOLERANCE]
                  [--filter_boxes FILTER_BOXES] [--kernel_size KERNEL_SIZE]
                  [--iterations ITERATIONS] [--weights WEIGHTS]
                  [--infer_mode INFER_MODE] [--length_norm LENGTH_NORM]
                  [--beam_width BEAM_WIDTH] [--num_groups NUM_GROUPS]
                  [--diversity_strength DIVERSITY_STRENGTH] [--top_k TOP_K]
                  [--top_p TOP_P] [--temperature TEMPERATURE] [--k K]
                  [--dictionary {False,match,POSmatch,characters}]
                  [--notransform_input] [--character CHARACTER]
luvia main: error: argument --dictionary: invalid choice: 'False' (choose from False, 'match', 'POSmatch', 'characters')
2025-08-24 17:06:51,116 - 2025-08-24 17:06:51 - Executing: luvia main --input '/home/alfredff/Toke/Maps for Alfred/Rigensgade bw_section.jpg' --blur_kernel 5,5 --blur_sigma 0 --block_size 15 --vthresh_C 3 --min_area 20 --max_area 2000 --min_aspect 0.1 --max_aspect 10.0 --min_vertices 6 --blur_kernel_size 5 --canny_thresh1 50 --canny_thresh2 150 --cc_min_area 20 --cc_max_area 2000 --contour_min_area 20 --contour_max_area 2000 --contour_min_vertices 5 --contour_max_vertices 0.001 --sigma 4 --separation_char 5 --hoofh_mode cca --min_area_segment 100 --dilation_kernel 90,10 --angle_tolerance 15 --filter_boxes inside_box --kernel_size 150,20 --iterations 1 --infer_mode diverse_beam --beam_width 3 --num_groups 3 --diversity_strength 0.5 --top_k 0 --top_p 0.9 --temperature 1.0 --k 1 --dictionary characters --character random
2025-08-24 17:06:58,421 - 2025-08-24 17:06:51 - Error: Traceback (most recent call last):
  File "/home/alfredff/Bio_Software/miniconda3/envs/luvia_py311/bin/luvia", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/home/alfredff/Toke/LUVIA/src/luvia/main.py", line 95, in main
    largs = LUVIAargs.main()
            ^^^^^^^^^^^^^^^^
  File "/home/alfredff/Toke/LUVIA/src/luvia/arguments.py", line 163, in main
    arguments_parse = LUVIAargs.fix_args(arguments_parse)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/alfredff/Toke/LUVIA/src/luvia/arguments.py", line 117, in fix_args
    if "blur_kernel" in arguments_parse._actions:
                        ^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'Namespace' object has no attribute '_actions'
2025-08-24 17:13:47,430 - 2025-08-24 17:13:47 - Executing: luvia main --input '/home/alfredff/Toke/Maps for Alfred/Rigensgade bw_section.jpg' --blur_kernel 5,5 --blur_sigma 0 --block_size 15 --vthresh_C 3 --min_area 20 --max_area 2000 --min_aspect 0.1 --max_aspect 10.0 --min_vertices 6 --blur_kernel_size 5 --canny_thresh1 50 --canny_thresh2 150 --cc_min_area 20 --cc_max_area 2000 --contour_min_area 20 --contour_max_area 2000 --contour_min_vertices 5 --contour_max_vertices 0.001 --sigma 4 --separation_char 5 --hoofh_mode cca --min_area_segment 100 --dilation_kernel 90,10 --angle_tolerance 15 --filter_boxes inside_box --kernel_size 150,20 --iterations 1 --infer_mode diverse_beam --beam_width 3 --num_groups 3 --diversity_strength 0.5 --top_k 0 --top_p 0.9 --temperature 1.0 --k 1 --dictionary characters --character random
2025-08-24 17:13:54,818 - 2025-08-24 17:13:47 - Error: Traceback (most recent call last):
  File "/home/alfredff/Bio_Software/miniconda3/envs/luvia_py311/bin/luvia", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/home/alfredff/Toke/LUVIA/src/luvia/main.py", line 96, in main
    l = LUVIA(out_folder=largs.output, mode=largs.command)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/alfredff/Toke/LUVIA/src/luvia/main.py", line 22, in __init__
    self.out_module = OutUtils(base_folder=out_folder)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/alfredff/Toke/LUVIA/src/luvia/utils/output_utils.py", line 13, in __init__
    self.output_folder, self.name = self.create_outfolder(base_folder)
                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/alfredff/Toke/LUVIA/src/luvia/utils/output_utils.py", line 39, in create_outfolder
    folder_path = Path(base_folder) / name_folder
                  ^^^^^^^^^^^^^^^^^
  File "/home/alfredff/Bio_Software/miniconda3/envs/luvia_py311/lib/python3.11/pathlib.py", line 871, in __new__
    self = cls._from_parts(args)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/alfredff/Bio_Software/miniconda3/envs/luvia_py311/lib/python3.11/pathlib.py", line 509, in _from_parts
    drv, root, parts = self._parse_args(args)
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/alfredff/Bio_Software/miniconda3/envs/luvia_py311/lib/python3.11/pathlib.py", line 493, in _parse_args
    a = os.fspath(a)
        ^^^^^^^^^^^^
TypeError: expected str, bytes or os.PathLike object, not NoneType
2025-08-24 17:45:02,587 - 2025-08-24 17:45:02 - Executing: luvia main --input '/home/alfredff/Toke/Maps for Alfred/Rigensgade bw_section.jpg' --output_dir /home/alfredff/Toke/LUVIA/test --blur_kernel 5,5 --blur_sigma 0 --block_size 15 --vthresh_C 3 --min_area 20 --max_area 2000 --min_aspect 0.1 --max_aspect 10.0 --min_vertices 6 --blur_kernel_size 5 --canny_thresh1 50 --canny_thresh2 150 --cc_min_area 20 --cc_max_area 2000 --contour_min_area 20 --contour_max_area 2000 --contour_min_vertices 5 --contour_max_vertices 0.001 --sigma 4 --separation_char 5 --hoofh_mode cca --min_area_segment 100 --dilation_kernel 90,10 --angle_tolerance 15 --filter_boxes inside_box --kernel_size 150,20 --iterations 1 --infer_mode diverse_beam --beam_width 3 --num_groups 3 --diversity_strength 0.5 --top_k 0 --top_p 0.9 --temperature 1.0 --k 1 --dictionary characters --character random
2025-08-24 17:45:09,950 - 2025-08-24 17:45:02 - Error: usage: luvia [-h] {main,clean,tongue,hoof,straw,spiral} ...
luvia: error: unrecognized arguments: --output_dir /home/alfredff/Toke/LUVIA/test
2025-08-24 17:46:22,582 - 2025-08-24 17:46:22 - Executing: luvia main --input '/home/alfredff/Toke/Maps for Alfred/Rigensgade bw_section.jpg' --output /home/alfredff/Toke/LUVIA/test --blur_kernel 5,5 --blur_sigma 0 --block_size 15 --vthresh_C 3 --min_area 20 --max_area 2000 --min_aspect 0.1 --max_aspect 10.0 --min_vertices 6 --blur_kernel_size 5 --canny_thresh1 50 --canny_thresh2 150 --cc_min_area 20 --cc_max_area 2000 --contour_min_area 20 --contour_max_area 2000 --contour_min_vertices 5 --contour_max_vertices 0.001 --sigma 4 --separation_char 5 --hoofh_mode cca --min_area_segment 100 --dilation_kernel 90,10 --angle_tolerance 15 --filter_boxes inside_box --kernel_size 150,20 --iterations 1 --infer_mode diverse_beam --beam_width 3 --num_groups 3 --diversity_strength 0.5 --top_k 0 --top_p 0.9 --temperature 1.0 --k 1 --dictionary characters --character random
2025-08-24 17:46:31,573 - 2025-08-24 17:46:22 - Error: Traceback (most recent call last):
  File "/home/alfredff/Bio_Software/miniconda3/envs/luvia_py311/bin/luvia", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/home/alfredff/Toke/LUVIA/src/luvia/main.py", line 111, in main
    l.main(image_path = largs.input, rotate_image=largs.rotate_img,
  File "/home/alfredff/Toke/LUVIA/src/luvia/main.py", line 51, in main
    lines = segmenter.extract_groups(image_rotated, filter_boxes)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/alfredff/Toke/LUVIA/src/luvia/hoof/hoof.py", line 97, in extract_groups
    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, self.dilation_kernel)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Can't parse 'ksize'. Sequence item with index 0 has a wrong type
2025-08-24 17:48:22,160 - 2025-08-24 17:48:22 - Executing: luvia main --input '/home/alfredff/Toke/Maps for Alfred/Rigensgade bw_section.jpg' --output /home/alfredff/Toke/LUVIA/test --blur_kernel 5,5 --blur_sigma 0 --block_size 15 --vthresh_C 3 --min_area 20 --max_area 2000 --min_aspect 0.1 --max_aspect 10.0 --min_vertices 6 --blur_kernel_size 5 --canny_thresh1 50 --canny_thresh2 150 --cc_min_area 20 --cc_max_area 2000 --contour_min_area 20 --contour_max_area 2000 --contour_min_vertices 5 --contour_max_vertices 0.001 --sigma 4 --separation_char 5 --hoofh_mode cca --min_area_segment 100 --dilation_kernel 90,10 --angle_tolerance 15 --filter_boxes inside_box --kernel_size 150,20 --iterations 1 --infer_mode diverse_beam --beam_width 3 --num_groups 3 --diversity_strength 0.5 --top_k 0 --top_p 0.9 --temperature 1.0 --k 1 --dictionary characters --character random
2025-08-24 17:48:31,444 - 2025-08-24 17:48:22 - Output: ('90', '10')
2025-08-24 17:48:31,444 - 2025-08-24 17:48:22 - Error: Traceback (most recent call last):
  File "/home/alfredff/Bio_Software/miniconda3/envs/luvia_py311/bin/luvia", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/home/alfredff/Toke/LUVIA/src/luvia/main.py", line 111, in main
    l.main(image_path = largs.input, rotate_image=largs.rotate_img,
  File "/home/alfredff/Toke/LUVIA/src/luvia/main.py", line 51, in main
    lines = segmenter.extract_groups(image_rotated, filter_boxes)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/alfredff/Toke/LUVIA/src/luvia/hoof/hoof.py", line 98, in extract_groups
    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, self.dilation_kernel)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Can't parse 'ksize'. Sequence item with index 0 has a wrong type
2025-08-24 17:49:06,432 - 2025-08-24 17:49:06 - Executing: luvia main --input '/home/alfredff/Toke/Maps for Alfred/Rigensgade bw_section.jpg' --output /home/alfredff/Toke/LUVIA/test --blur_kernel 5,5 --blur_sigma 0 --block_size 15 --vthresh_C 3 --min_area 20 --max_area 2000 --min_aspect 0.1 --max_aspect 10.0 --min_vertices 6 --blur_kernel_size 5 --canny_thresh1 50 --canny_thresh2 150 --cc_min_area 20 --cc_max_area 2000 --contour_min_area 20 --contour_max_area 2000 --contour_min_vertices 5 --contour_max_vertices 0.001 --sigma 4 --separation_char 5 --hoofh_mode cca --min_area_segment 100 --dilation_kernel 90,10 --angle_tolerance 15 --filter_boxes inside_box --kernel_size 150,20 --iterations 1 --infer_mode diverse_beam --beam_width 3 --num_groups 3 --diversity_strength 0.5 --top_k 0 --top_p 0.9 --temperature 1.0 --k 1 --dictionary characters --character random
2025-08-24 17:49:15,393 - 2025-08-24 17:49:06 - Output: (90, 10)
2025-08-24 17:49:15,393 - 2025-08-24 17:49:06 - Error: Traceback (most recent call last):
  File "/home/alfredff/Bio_Software/miniconda3/envs/luvia_py311/bin/luvia", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/home/alfredff/Toke/LUVIA/src/luvia/main.py", line 111, in main
    l.main(image_path = largs.input, rotate_image=largs.rotate_img,
  File "/home/alfredff/Toke/LUVIA/src/luvia/main.py", line 51, in main
    lines = segmenter.extract_groups(image_rotated, filter_boxes)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/alfredff/Toke/LUVIA/src/luvia/hoof/hoof.py", line 115, in extract_groups
    if area >= self.min_area:
       ^^^^^^^^^^^^^^^^^^^^^
numpy._core._exceptions._UFuncNoLoopError: ufunc 'greater_equal' did not contain a loop with signature matching types (<class 'numpy.dtypes.Int32DType'>, <class 'numpy.dtypes.StrDType'>) -> None
2025-08-24 17:57:42,029 - 2025-08-24 17:57:42 - Executing: luvia main --input '/home/alfredff/Toke/Maps for Alfred/Rigensgade bw_section.jpg' --output /home/alfredff/Toke/LUVIA/test --blur_kernel 5,5 --blur_sigma 0 --block_size 15 --vthresh_C 3 --min_area 20 --max_area 2000 --min_aspect 0.1 --max_aspect 10.0 --min_vertices 6 --blur_kernel_size 5 --canny_thresh1 50 --canny_thresh2 150 --cc_min_area 20 --cc_max_area 2000 --contour_min_area 20 --contour_max_area 2000 --contour_min_vertices 5 --contour_max_vertices 0.001 --sigma 4 --separation_char 5 --hoofh_mode cca --min_area_segment 100 --dilation_kernel 90,10 --angle_tolerance 15 --filter_boxes inside_box --kernel_size 150,20 --iterations 1 --infer_mode diverse_beam --beam_width 3 --num_groups 3 --diversity_strength 0.5 --top_k 0 --top_p 0.9 --temperature 1.0 --k 1 --dictionary characters --character random
2025-08-24 17:57:50,850 - 2025-08-24 17:57:42 - Output: 73052 100
2025-08-24 17:57:50,850 - 2025-08-24 17:57:42 - Error: Traceback (most recent call last):
  File "/home/alfredff/Bio_Software/miniconda3/envs/luvia_py311/bin/luvia", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/home/alfredff/Toke/LUVIA/src/luvia/main.py", line 111, in main
    l.main(image_path = largs.input, rotate_image=largs.rotate_img,
  File "/home/alfredff/Toke/LUVIA/src/luvia/main.py", line 51, in main
    lines = segmenter.extract_groups(image_rotated, filter_boxes)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/alfredff/Toke/LUVIA/src/luvia/hoof/hoof.py", line 113, in extract_groups
    if area >= self.min_area:
       ^^^^^^^^^^^^^^^^^^^^^
numpy._core._exceptions._UFuncNoLoopError: ufunc 'greater_equal' did not contain a loop with signature matching types (<class 'numpy.dtypes.Int32DType'>, <class 'numpy.dtypes.StrDType'>) -> None
2025-08-24 18:04:12,435 - 2025-08-24 18:04:12 - Executing: luvia main --input '/home/alfredff/Toke/Maps for Alfred/Rigensgade bw_section.jpg' --output /home/alfredff/Toke/LUVIA/test --blur_kernel 5,5 --blur_sigma 0 --block_size 15 --vthresh_C 3 --min_area 20 --max_area 2000 --min_aspect 0.1 --max_aspect 10.0 --min_vertices 6 --blur_kernel_size 5 --canny_thresh1 50 --canny_thresh2 150 --cc_min_area 20 --cc_max_area 2000 --contour_min_area 20 --contour_max_area 2000 --contour_min_vertices 5 --contour_max_vertices 0.001 --sigma 4 --separation_char 5 --hoofh_mode cca --min_area_segment 100 --dilation_kernel 90,10 --angle_tolerance 15 --filter_boxes inside_box --kernel_size 150,20 --iterations 1 --infer_mode diverse_beam --beam_width 3 --num_groups 3 --diversity_strength 0.5 --top_k 0 --top_p 0.9 --temperature 1.0 --k 1 --dictionary characters --character random
2025-08-24 18:04:21,913 - 2025-08-24 18:04:12 - Output: 73052 100.0
4769 100.0
21608 100.0
11903 100.0
5730 100.0
3936 100.0
5537 100.0
2025-08-24 18:04:21,914 - 2025-08-24 18:04:12 - Error: Traceback (most recent call last):
  File "/home/alfredff/Bio_Software/miniconda3/envs/luvia_py311/lib/python3.11/site-packages/torch/serialization.py", line 869, in _check_seekable
    f.seek(f.tell())
    ^^^^^^
AttributeError: 'NoneType' object has no attribute 'seek'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/alfredff/Bio_Software/miniconda3/envs/luvia_py311/bin/luvia", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/home/alfredff/Toke/LUVIA/src/luvia/main.py", line 111, in main
    l.main(image_path = largs.input, rotate_image=largs.rotate_img,
  File "/home/alfredff/Toke/LUVIA/src/luvia/main.py", line 66, in main
    straw.load_model(weights_straw)
  File "/home/alfredff/Toke/LUVIA/src/luvia/straw/straw.py", line 171, in load_model
    self.model.load_state_dict(torch.load(path, map_location=self.device, weights_only=True))
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/alfredff/Bio_Software/miniconda3/envs/luvia_py311/lib/python3.11/site-packages/torch/serialization.py", line 1484, in load
    with _open_file_like(f, "rb") as opened_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/alfredff/Bio_Software/miniconda3/envs/luvia_py311/lib/python3.11/site-packages/torch/serialization.py", line 764, in _open_file_like
    return _open_buffer_reader(name_or_buffer)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/alfredff/Bio_Software/miniconda3/envs/luvia_py311/lib/python3.11/site-packages/torch/serialization.py", line 749, in __init__
    _check_seekable(buffer)
  File "/home/alfredff/Bio_Software/miniconda3/envs/luvia_py311/lib/python3.11/site-packages/torch/serialization.py", line 872, in _check_seekable
    raise_err_msg(["seek", "tell"], e)
  File "/home/alfredff/Bio_Software/miniconda3/envs/luvia_py311/lib/python3.11/site-packages/torch/serialization.py", line 865, in raise_err_msg
    raise type(e)(msg)
AttributeError: 'NoneType' object has no attribute 'seek'. You can only torch.load from a file that is seekable. Please pre-load the data into a buffer like io.BytesIO and try to load from it instead.
2025-08-24 18:06:07,953 - 2025-08-24 18:06:07 - Executing: luvia main --input '/home/alfredff/Toke/Maps for Alfred/Rigensgade bw_section.jpg' --output /home/alfredff/Toke/LUVIA/test --blur_kernel 5,5 --blur_sigma 0 --block_size 15 --vthresh_C 3 --min_area 20 --max_area 2000 --min_aspect 0.1 --max_aspect 10.0 --min_vertices 6 --blur_kernel_size 5 --canny_thresh1 50 --canny_thresh2 150 --cc_min_area 20 --cc_max_area 2000 --contour_min_area 20 --contour_max_area 2000 --contour_min_vertices 5 --contour_max_vertices 0.001 --sigma 4 --separation_char 5 --hoofh_mode cca --min_area_segment 100 --dilation_kernel 90,10 --angle_tolerance 15 --filter_boxes inside_box --kernel_size 150,20 --iterations 1 --weights src/luvia/data/weights/weights2_speakcorpus_e60.pt --infer_mode diverse_beam --beam_width 3 --num_groups 3 --diversity_strength 0.5 --top_k 0 --top_p 0.9 --temperature 1.0 --k 1 --dictionary characters --character random
2025-08-24 18:06:20,020 - 2025-08-24 18:06:07 - Output: 73052 100.0
4769 100.0
21608 100.0
11903 100.0
5730 100.0
3936 100.0
5537 100.0
{'infer_mode': 'diverse_beam', 'length_norm': True, 'beam_width': 3.0, 'num_groups': 3.0, 'diversity_strength': 0.5, 'top_k': 0.0, 'top_p': 0.9, 'temperature': 1.0, 'k': 1.0}
{'infer_mode': 'diverse_beam', 'length_norm': True, 'beam_width': 3.0, 'num_groups': 3.0, 'diversity_strength': 0.5, 'top_k': 0.0, 'top_p': 0.9, 'temperature': 1.0, 'k': 1.0}
2025-08-24 18:06:20,020 - 2025-08-24 18:06:07 - Error: 0%|          | 0/6 [00:00<?, ?it/s]

0it [00:00, ?it/s][A
0it [00:00, ?it/s]

 17%|        | 1/6 [00:00<00:02,  1.82it/s]

0it [00:00, ?it/s][A
0it [00:00, ?it/s]

 17%|        | 1/6 [00:02<00:10,  2.18s/it]
Traceback (most recent call last):
  File "/home/alfredff/Bio_Software/miniconda3/envs/luvia_py311/bin/luvia", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/home/alfredff/Toke/LUVIA/src/luvia/main.py", line 111, in main
    l.main(image_path = largs.input, rotate_image=largs.rotate_img,
  File "/home/alfredff/Toke/LUVIA/src/luvia/main.py", line 82, in main
    results = straw.infer_model(dataloader, **infer_model_args)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/alfredff/Toke/LUVIA/src/luvia/straw/straw.py", line 122, in infer_model
    output, act1, act2 = self.model.infer(image=images[i], start_token=self.vocab_dict['<START>'], end_token=self.vocab_dict['<END>'],
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/alfredff/Toke/LUVIA/src/luvia/straw/model/model.py", line 28, in infer
    infer_result = self.infer_diverse_beam(features, start_token, end_token, beam_width=beam_width,
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/alfredff/Toke/LUVIA/src/luvia/straw/model/model.py", line 47, in infer_diverse_beam
    return self.decoder.generate_diverse_beam_search(features, start_token, end_token, beam_width, num_groups,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/alfredff/Toke/LUVIA/src/luvia/straw/model/decoder.py", line 119, in generate_diverse_beam_search
    beams = [[([start_token], 0.0, h, c)] for _ in range(num_groups)]
                                                   ^^^^^^^^^^^^^^^^^
TypeError: 'float' object cannot be interpreted as an integer
2025-08-24 18:06:31,185 - 2025-08-24 18:06:31 - Executing: luvia main --input '/home/alfredff/Toke/Maps for Alfred/Rigensgade bw_section.jpg' --output /home/alfredff/Toke/LUVIA/test --blur_kernel 5,5 --blur_sigma 0 --block_size 15 --vthresh_C 3 --min_area 20 --max_area 2000 --min_aspect 0.1 --max_aspect 10.0 --min_vertices 6 --blur_kernel_size 5 --canny_thresh1 50 --canny_thresh2 150 --cc_min_area 20 --cc_max_area 2000 --contour_min_area 20 --contour_max_area 2000 --contour_min_vertices 5 --contour_max_vertices 0.001 --sigma 4 --separation_char 5 --hoofh_mode cca --min_area_segment 100 --dilation_kernel 90,10 --angle_tolerance 15 --filter_boxes inside_box --kernel_size 150,20 --iterations 1 --weights src/luvia/data/weights/weights2_speakcorpus_e60.pt --infer_mode diverse_beam --length_norm --beam_width 3 --num_groups 3 --diversity_strength 0.5 --top_k 0 --top_p 0.9 --temperature 1.0 --k 1 --dictionary characters --character random
2025-08-24 18:06:38,822 - 2025-08-24 18:06:31 - Error: usage: luvia main [-h] [-i INPUT] [-o OUTPUT]
                  [--clean_mode {OTSA,simple,False}] [--rotate_img ROTATE_IMG]
                  [-v] [--blur_kernel BLUR_KERNEL] [--blur_sigma BLUR_SIGMA]
                  [--block_size BLOCK_SIZE] [--vthresh_C VTHRESH_C]
                  [--min_area MIN_AREA] [--max_area MAX_AREA]
                  [--min_aspect MIN_ASPECT] [--max_aspect MAX_ASPECT]
                  [--min_vertices MIN_VERTICES]
                  [--blur_kernel_size BLUR_KERNEL_SIZE]
                  [--canny_thresh1 CANNY_THRESH1]
                  [--canny_thresh2 CANNY_THRESH2] [--cc_min_area CC_MIN_AREA]
                  [--cc_max_area CC_MAX_AREA]
                  [--contour_min_area CONTOUR_MIN_AREA]
                  [--contour_max_area CONTOUR_MAX_AREA]
                  [--contour_min_vertices CONTOUR_MIN_VERTICES]
                  [--contour_max_vertices CONTOUR_MAX_VERTICES]
                  [--sigma SIGMA] [--separation_char SEPARATION_CHAR]
                  [--hoofh_mode {cca,threshold}] [--filter_angle FILTER_ANGLE]
                  [--min_area_segment MIN_AREA_SEGMENT]
                  [--dilation_kernel DILATION_KERNEL]
                  [--angle_tolerance ANGLE_TOLERANCE]
                  [--filter_boxes FILTER_BOXES] [--kernel_size KERNEL_SIZE]
                  [--iterations ITERATIONS] [--weights WEIGHTS]
                  [--infer_mode INFER_MODE] [--length_norm LENGTH_NORM]
                  [--beam_width BEAM_WIDTH] [--num_groups NUM_GROUPS]
                  [--diversity_strength DIVERSITY_STRENGTH] [--top_k TOP_K]
                  [--top_p TOP_P] [--temperature TEMPERATURE] [--k K]
                  [--dictionary {False,match,POSmatch,characters}]
                  [--notransform_input] [--character CHARACTER]
luvia main: error: argument --length_norm: expected one argument
2025-08-24 18:07:18,911 - 2025-08-24 18:07:18 - Executing: luvia main --input '/home/alfredff/Toke/Maps for Alfred/Rigensgade bw_section.jpg' --output /home/alfredff/Toke/LUVIA/test --blur_kernel 5,5 --blur_sigma 0 --block_size 15 --vthresh_C 3 --min_area 20 --max_area 2000 --min_aspect 0.1 --max_aspect 10.0 --min_vertices 6 --blur_kernel_size 5 --canny_thresh1 50 --canny_thresh2 150 --cc_min_area 20 --cc_max_area 2000 --contour_min_area 20 --contour_max_area 2000 --contour_min_vertices 5 --contour_max_vertices 0.001 --sigma 4 --separation_char 5 --hoofh_mode cca --min_area_segment 100 --dilation_kernel 90,10 --angle_tolerance 15 --filter_boxes inside_box --kernel_size 150,20 --iterations 1 --weights src/luvia/data/weights/weights2_speakcorpus_e60.pt --infer_mode diverse_beam --length_norm --beam_width 3 --num_groups 3 --diversity_strength 0.5 --top_k 0 --top_p 0.9 --temperature 1.0 --k 1 --dictionary characters --character random
2025-08-24 18:07:31,034 - 2025-08-24 18:07:18 - Output: 73052 100.0
4769 100.0
21608 100.0
11903 100.0
5730 100.0
3936 100.0
5537 100.0
{'infer_mode': 'diverse_beam', 'length_norm': True, 'beam_width': 3.0, 'num_groups': 3.0, 'diversity_strength': 0.5, 'top_k': 0.0, 'top_p': 0.9, 'temperature': 1.0, 'k': 1.0}
{'infer_mode': 'diverse_beam', 'length_norm': True, 'beam_width': 3.0, 'num_groups': 3.0, 'diversity_strength': 0.5, 'top_k': 0.0, 'top_p': 0.9, 'temperature': 1.0, 'k': 1.0}
2025-08-24 18:07:31,034 - 2025-08-24 18:07:18 - Error: 0%|          | 0/6 [00:00<?, ?it/s]

0it [00:00, ?it/s][A
0it [00:00, ?it/s]

 17%|        | 1/6 [00:00<00:02,  1.84it/s]

0it [00:00, ?it/s][A
0it [00:00, ?it/s]

 17%|        | 1/6 [00:02<00:10,  2.11s/it]
Traceback (most recent call last):
  File "/home/alfredff/Bio_Software/miniconda3/envs/luvia_py311/bin/luvia", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/home/alfredff/Toke/LUVIA/src/luvia/main.py", line 111, in main
    l.main(image_path = largs.input, rotate_image=largs.rotate_img,
  File "/home/alfredff/Toke/LUVIA/src/luvia/main.py", line 82, in main
    results = straw.infer_model(dataloader, **infer_model_args)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/alfredff/Toke/LUVIA/src/luvia/straw/straw.py", line 122, in infer_model
    output, act1, act2 = self.model.infer(image=images[i], start_token=self.vocab_dict['<START>'], end_token=self.vocab_dict['<END>'],
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/alfredff/Toke/LUVIA/src/luvia/straw/model/model.py", line 28, in infer
    infer_result = self.infer_diverse_beam(features, start_token, end_token, beam_width=beam_width,
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/alfredff/Toke/LUVIA/src/luvia/straw/model/model.py", line 47, in infer_diverse_beam
    return self.decoder.generate_diverse_beam_search(features, start_token, end_token, beam_width, num_groups,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/alfredff/Toke/LUVIA/src/luvia/straw/model/decoder.py", line 119, in generate_diverse_beam_search
    beams = [[([start_token], 0.0, h, c)] for _ in range(num_groups)]
                                                   ^^^^^^^^^^^^^^^^^
TypeError: 'float' object cannot be interpreted as an integer
2025-08-24 18:10:31,907 - 2025-08-24 18:10:31 - Executing: luvia main --input '/home/alfredff/Toke/Maps for Alfred/Rigensgade bw_section.jpg' --output /home/alfredff/Toke/LUVIA/test --blur_kernel 5,5 --blur_sigma 0 --block_size 15 --vthresh_C 3 --min_area 20 --max_area 2000 --min_aspect 0.1 --max_aspect 10.0 --min_vertices 6 --blur_kernel_size 5 --canny_thresh1 50 --canny_thresh2 150 --cc_min_area 20 --cc_max_area 2000 --contour_min_area 20 --contour_max_area 2000 --contour_min_vertices 5 --contour_max_vertices 0.001 --sigma 4 --separation_char 5 --hoofh_mode cca --min_area_segment 100 --dilation_kernel 90,10 --angle_tolerance 15 --filter_boxes inside_box --kernel_size 150,20 --iterations 1 --weights src/luvia/data/weights/weights2_speakcorpus_e60.pt --infer_mode diverse_beam --length_norm --beam_width 3 --num_groups 3 --diversity_strength 0.5 --top_k 0 --top_p 0.9 --temperature 1.0 --k 1 --dictionary characters --character random
2025-08-24 18:10:44,225 - 2025-08-24 18:10:31 - Output: 73052 100.0
4769 100.0
21608 100.0
11903 100.0
5730 100.0
3936 100.0
5537 100.0
{'infer_mode': 'diverse_beam', 'length_norm': True, 'beam_width': 3, 'num_groups': 3, 'diversity_strength': 0.5, 'top_k': 0.0, 'top_p': 0.9, 'temperature': 1.0, 'k': 1.0}
{'infer_mode': 'diverse_beam', 'length_norm': True, 'beam_width': 3, 'num_groups': 3, 'diversity_strength': 0.5, 'top_k': 0.0, 'top_p': 0.9, 'temperature': 1.0, 'k': 1.0}
2025-08-24 18:10:44,225 - 2025-08-24 18:10:31 - Error: 0%|          | 0/6 [00:00<?, ?it/s]

0it [00:00, ?it/s][A
0it [00:00, ?it/s]

 17%|        | 1/6 [00:00<00:02,  1.80it/s]

0it [00:00, ?it/s][A
0it [00:00, ?it/s]

 17%|        | 1/6 [00:02<00:11,  2.29s/it]
Traceback (most recent call last):
  File "/home/alfredff/Bio_Software/miniconda3/envs/luvia_py311/bin/luvia", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/home/alfredff/Toke/LUVIA/src/luvia/main.py", line 111, in main
    l.main(image_path = largs.input, rotate_image=largs.rotate_img,
  File "/home/alfredff/Toke/LUVIA/src/luvia/main.py", line 82, in main
    results = straw.infer_model(dataloader, **infer_model_args)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/alfredff/Toke/LUVIA/src/luvia/straw/straw.py", line 122, in infer_model
    output, act1, act2 = self.model.infer(image=images[i], start_token=self.vocab_dict['<START>'], end_token=self.vocab_dict['<END>'],
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/alfredff/Toke/LUVIA/src/luvia/straw/model/model.py", line 28, in infer
    infer_result = self.infer_diverse_beam(features, start_token, end_token, beam_width=beam_width,
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/alfredff/Toke/LUVIA/src/luvia/straw/model/model.py", line 47, in infer_diverse_beam
    return self.decoder.generate_diverse_beam_search(features, start_token, end_token, beam_width, num_groups,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/alfredff/Toke/LUVIA/src/luvia/straw/model/decoder.py", line 168, in generate_diverse_beam_search
    sorted_sequences = sorted(all_sequences, key=lambda x: x[1] / len(x[0]) if length_norm else x[1],
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: slice indices must be integers or None or have an __index__ method
2025-08-24 18:19:18,332 - 2025-08-24 18:19:18 - Executing: luvia main --input '/home/alfredff/Toke/Maps for Alfred/Rigensgade bw_section.jpg' --output /home/alfredff/Toke/LUVIA/test --blur_kernel 5,5 --blur_sigma 0 --block_size 15 --vthresh_C 3 --min_area 20 --max_area 2000 --min_aspect 0.1 --max_aspect 10.0 --min_vertices 6 --blur_kernel_size 5 --canny_thresh1 50 --canny_thresh2 150 --cc_min_area 20 --cc_max_area 2000 --contour_min_area 20 --contour_max_area 2000 --contour_min_vertices 5 --contour_max_vertices 0.001 --sigma 4 --separation_char 5 --hoofh_mode cca --min_area_segment 100 --dilation_kernel 90,10 --angle_tolerance 15 --filter_boxes inside_box --kernel_size 150,20 --iterations 1 --weights src/luvia/data/weights/weights2_speakcorpus_e60.pt --infer_mode diverse_beam --length_norm --beam_width 3 --num_groups 3 --diversity_strength 0.5 --top_k 0 --top_p 0.9 --temperature 1.0 --k 1 --dictionary characters --character random
2025-08-24 18:19:30,804 - 2025-08-24 18:19:18 - Output: 73052 100.0
4769 100.0
21608 100.0
11903 100.0
5730 100.0
3936 100.0
5537 100.0
{'infer_mode': 'diverse_beam', 'length_norm': True, 'beam_width': 3, 'num_groups': 3, 'diversity_strength': 0.5, 'top_k': 0.0, 'top_p': 0.9, 'temperature': 1.0, 'k': 1.0}
{'infer_mode': 'diverse_beam', 'length_norm': True, 'beam_width': 3, 'num_groups': 3, 'diversity_strength': 0.5, 'top_k': 0.0, 'top_p': 0.9, 'temperature': 1.0, 'k': 1.0}
{'<PAD>': 0, '<START>': 1, '<END>': 2, 'a': 3, 'b': 4, 'c': 5, 'd': 6, 'e': 7, 'f': 8, 'g': 9, 'h': 10, 'i': 11, 'j': 12, 'k': 13, 'l': 14, 'm': 15, 'n': 16, 'o': 17, 'p': 18, 'q': 19, 'r': 20, 's': 21, 't': 22, 'u': 23, 'v': 24, 'w': 25, 'x': 26, 'y': 27, 'z': 28}
2025-08-24 18:19:30,804 - 2025-08-24 18:19:18 - Error: 0%|          | 0/6 [00:00<?, ?it/s]

0it [00:00, ?it/s][A
0it [00:00, ?it/s]

 17%|        | 1/6 [00:00<00:02,  2.05it/s]

0it [00:00, ?it/s][A
0it [00:00, ?it/s]

 17%|        | 1/6 [00:02<00:10,  2.01s/it]
Traceback (most recent call last):
  File "/home/alfredff/Bio_Software/miniconda3/envs/luvia_py311/bin/luvia", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/home/alfredff/Toke/LUVIA/src/luvia/main.py", line 111, in main
    l.main(image_path = largs.input, rotate_image=largs.rotate_img,
  File "/home/alfredff/Toke/LUVIA/src/luvia/main.py", line 82, in main
    results = straw.infer_model(dataloader, **infer_model_args)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/alfredff/Toke/LUVIA/src/luvia/straw/straw.py", line 122, in infer_model
    output, act1, act2 = self.model.infer(image=images[i], start_token=self.vocab_dict['<START>'], end_token=self.vocab_dict['<END>'],
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/alfredff/Toke/LUVIA/src/luvia/straw/model/model.py", line 28, in infer
    infer_result = self.infer_diverse_beam(features, start_token, end_token, beam_width=beam_width,
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/alfredff/Toke/LUVIA/src/luvia/straw/model/model.py", line 47, in infer_diverse_beam
    return self.decoder.generate_diverse_beam_search(features, start_token, end_token, beam_width, num_groups,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/alfredff/Toke/LUVIA/src/luvia/straw/model/decoder.py", line 168, in generate_diverse_beam_search
    sorted_sequences = sorted(all_sequences, key=lambda x: x[1] / len(x[0]) if length_norm else x[1],
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: slice indices must be integers or None or have an __index__ method
2025-08-24 18:25:50,572 - 2025-08-24 18:25:50 - Executing: luvia main --input '/home/alfredff/Toke/Maps for Alfred/Rigensgade bw_section.jpg' --output /home/alfredff/Toke/LUVIA/test --blur_kernel 5,5 --blur_sigma 0 --block_size 15 --vthresh_C 3 --min_area 20 --max_area 2000 --min_aspect 0.1 --max_aspect 10.0 --min_vertices 6 --blur_kernel_size 5 --canny_thresh1 50 --canny_thresh2 150 --cc_min_area 20 --cc_max_area 2000 --contour_min_area 20 --contour_max_area 2000 --contour_min_vertices 5 --contour_max_vertices 0.001 --sigma 4 --separation_char 5 --hoofh_mode cca --min_area_segment 100 --dilation_kernel 90,10 --angle_tolerance 15 --filter_boxes inside_box --kernel_size 150,20 --iterations 1 --weights src/luvia/data/weights/weights2_speakcorpus_e60.pt --infer_mode diverse_beam --length_norm --beam_width 3 --num_groups 3 --diversity_strength 0.5 --top_k 0 --top_p 0.9 --temperature 1.0 --k 2 --dictionary characters --character random
2025-08-24 18:26:02,522 - 2025-08-24 18:25:50 - Output: 73052 100.0
4769 100.0
21608 100.0
11903 100.0
5730 100.0
3936 100.0
5537 100.0
{'infer_mode': 'diverse_beam', 'length_norm': True, 'beam_width': 3, 'num_groups': 3, 'diversity_strength': 0.5, 'top_k': 0.0, 'top_p': 0.9, 'temperature': 1.0, 'k': 2.0}
{'infer_mode': 'diverse_beam', 'length_norm': True, 'beam_width': 3, 'num_groups': 3, 'diversity_strength': 0.5, 'top_k': 0.0, 'top_p': 0.9, 'temperature': 1.0, 'k': 2.0}
{'<PAD>': 0, '<START>': 1, '<END>': 2, 'a': 3, 'b': 4, 'c': 5, 'd': 6, 'e': 7, 'f': 8, 'g': 9, 'h': 10, 'i': 11, 'j': 12, 'k': 13, 'l': 14, 'm': 15, 'n': 16, 'o': 17, 'p': 18, 'q': 19, 'r': 20, 's': 21, 't': 22, 'u': 23, 'v': 24, 'w': 25, 'x': 26, 'y': 27, 'z': 28}
2025-08-24 18:26:02,522 - 2025-08-24 18:25:50 - Error: 0%|          | 0/6 [00:00<?, ?it/s]

0it [00:00, ?it/s][A
0it [00:00, ?it/s]

 17%|        | 1/6 [00:00<00:02,  2.17it/s]

0it [00:00, ?it/s][A
0it [00:00, ?it/s]

 17%|        | 1/6 [00:02<00:10,  2.01s/it]
Traceback (most recent call last):
  File "/home/alfredff/Bio_Software/miniconda3/envs/luvia_py311/bin/luvia", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/home/alfredff/Toke/LUVIA/src/luvia/main.py", line 111, in main
    l.main(image_path = largs.input, rotate_image=largs.rotate_img,
  File "/home/alfredff/Toke/LUVIA/src/luvia/main.py", line 82, in main
    results = straw.infer_model(dataloader, **infer_model_args)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/alfredff/Toke/LUVIA/src/luvia/straw/straw.py", line 122, in infer_model
    output, act1, act2 = self.model.infer(image=images[i], start_token=self.vocab_dict['<START>'], end_token=self.vocab_dict['<END>'],
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/alfredff/Toke/LUVIA/src/luvia/straw/model/model.py", line 28, in infer
    infer_result = self.infer_diverse_beam(features, start_token, end_token, beam_width=beam_width,
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/alfredff/Toke/LUVIA/src/luvia/straw/model/model.py", line 47, in infer_diverse_beam
    return self.decoder.generate_diverse_beam_search(features, start_token, end_token, beam_width, num_groups,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/alfredff/Toke/LUVIA/src/luvia/straw/model/decoder.py", line 168, in generate_diverse_beam_search
    sorted_sequences = sorted(all_sequences, key=lambda x: x[1] / len(x[0]) if length_norm else x[1],
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: slice indices must be integers or None or have an __index__ method
2025-08-24 18:29:07,089 - 2025-08-24 18:29:07 - Executing: luvia main --input '/home/alfredff/Toke/Maps for Alfred/Rigensgade bw_section.jpg' --output /home/alfredff/Toke/LUVIA/test --blur_kernel 5,5 --blur_sigma 0 --block_size 15 --vthresh_C 3 --min_area 20 --max_area 2000 --min_aspect 0.1 --max_aspect 10.0 --min_vertices 6 --blur_kernel_size 5 --canny_thresh1 50 --canny_thresh2 150 --cc_min_area 20 --cc_max_area 2000 --contour_min_area 20 --contour_max_area 2000 --contour_min_vertices 5 --contour_max_vertices 0.001 --sigma 4 --separation_char 5 --hoofh_mode cca --min_area_segment 100 --dilation_kernel 90,10 --angle_tolerance 15 --filter_boxes inside_box --kernel_size 150,20 --iterations 1 --weights src/luvia/data/weights/weights2_speakcorpus_e60.pt --infer_mode diverse_beam --length_norm --beam_width 3 --num_groups 3 --diversity_strength 0.5 --top_k 0 --top_p 0.9 --temperature 1.0 --k 2 --dictionary characters --character random
2025-08-24 18:29:19,041 - 2025-08-24 18:29:07 - Output: 73052 100.0
4769 100.0
21608 100.0
11903 100.0
5730 100.0
3936 100.0
5537 100.0
{'infer_mode': 'diverse_beam', 'length_norm': True, 'beam_width': 3, 'num_groups': 3, 'diversity_strength': 0.5, 'top_k': 0.0, 'top_p': 0.9, 'temperature': 1.0, 'k': 2.0}
{'infer_mode': 'diverse_beam', 'length_norm': True, 'beam_width': 3, 'num_groups': 3, 'diversity_strength': 0.5, 'top_k': 0.0, 'top_p': 0.9, 'temperature': 1.0, 'k': 2.0}
{'<PAD>': 0, '<START>': 1, '<END>': 2, 'a': 3, 'b': 4, 'c': 5, 'd': 6, 'e': 7, 'f': 8, 'g': 9, 'h': 10, 'i': 11, 'j': 12, 'k': 13, 'l': 14, 'm': 15, 'n': 16, 'o': 17, 'p': 18, 'q': 19, 'r': 20, 's': 21, 't': 22, 'u': 23, 'v': 24, 'w': 25, 'x': 26, 'y': 27, 'z': 28}
[([1, 10, 7, 7, 20, 7, 7, 21, 2], -8.184185415506363), ([1, 23, 18, 17, 20, 7, 4, 7, 20, 2], -9.639341861009598), ([1, 23, 18, 18, 7, 20, 2], -6.009606719017029)] True
2025-08-24 18:29:19,041 - 2025-08-24 18:29:07 - Error: 0%|          | 0/6 [00:00<?, ?it/s]

0it [00:00, ?it/s][A
0it [00:00, ?it/s]

 17%|        | 1/6 [00:00<00:02,  2.00it/s]

0it [00:00, ?it/s][A
0it [00:00, ?it/s]

 17%|        | 1/6 [00:02<00:10,  2.10s/it]
Traceback (most recent call last):
  File "/home/alfredff/Bio_Software/miniconda3/envs/luvia_py311/bin/luvia", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/home/alfredff/Toke/LUVIA/src/luvia/main.py", line 111, in main
    l.main(image_path = largs.input, rotate_image=largs.rotate_img,
  File "/home/alfredff/Toke/LUVIA/src/luvia/main.py", line 82, in main
    results = straw.infer_model(dataloader, **infer_model_args)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/alfredff/Toke/LUVIA/src/luvia/straw/straw.py", line 122, in infer_model
    output, act1, act2 = self.model.infer(image=images[i], start_token=self.vocab_dict['<START>'], end_token=self.vocab_dict['<END>'],
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/alfredff/Toke/LUVIA/src/luvia/straw/model/model.py", line 28, in infer
    infer_result = self.infer_diverse_beam(features, start_token, end_token, beam_width=beam_width,
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/alfredff/Toke/LUVIA/src/luvia/straw/model/model.py", line 47, in infer_diverse_beam
    return self.decoder.generate_diverse_beam_search(features, start_token, end_token, beam_width, num_groups,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/alfredff/Toke/LUVIA/src/luvia/straw/model/decoder.py", line 168, in generate_diverse_beam_search
    sorted_sequences = sorted(all_sequences, key=lambda x: x[1] / len(x[0]) if length_norm else x[1],
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: slice indices must be integers or None or have an __index__ method
2025-08-24 18:31:55,434 - 2025-08-24 18:31:55 - Executing: luvia main --input '/home/alfredff/Toke/Maps for Alfred/Rigensgade bw_section.jpg' --output /home/alfredff/Toke/LUVIA/test --blur_kernel 5,5 --blur_sigma 0 --block_size 15 --vthresh_C 3 --min_area 20 --max_area 2000 --min_aspect 0.1 --max_aspect 10.0 --min_vertices 6 --blur_kernel_size 5 --canny_thresh1 50 --canny_thresh2 150 --cc_min_area 20 --cc_max_area 2000 --contour_min_area 20 --contour_max_area 2000 --contour_min_vertices 5 --contour_max_vertices 0.001 --sigma 4 --separation_char 5 --hoofh_mode cca --min_area_segment 100 --dilation_kernel 90,10 --angle_tolerance 15 --filter_boxes inside_box --kernel_size 150,20 --iterations 1 --weights src/luvia/data/weights/weights2_speakcorpus_e60.pt --infer_mode diverse_beam --beam_width 3 --num_groups 3 --diversity_strength 0.5 --top_k 0 --top_p 0.9 --temperature 1.0 --k 2 --dictionary characters --character random
2025-08-24 18:32:07,328 - 2025-08-24 18:31:55 - Output: 73052 100.0
4769 100.0
21608 100.0
11903 100.0
5730 100.0
3936 100.0
5537 100.0
{'infer_mode': 'diverse_beam', 'length_norm': False, 'beam_width': 3, 'num_groups': 3, 'diversity_strength': 0.5, 'top_k': 0.0, 'top_p': 0.9, 'temperature': 1.0, 'k': 2.0}
{'infer_mode': 'diverse_beam', 'length_norm': False, 'beam_width': 3, 'num_groups': 3, 'diversity_strength': 0.5, 'top_k': 0.0, 'top_p': 0.9, 'temperature': 1.0, 'k': 2.0}
{'<PAD>': 0, '<START>': 1, '<END>': 2, 'a': 3, 'b': 4, 'c': 5, 'd': 6, 'e': 7, 'f': 8, 'g': 9, 'h': 10, 'i': 11, 'j': 12, 'k': 13, 'l': 14, 'm': 15, 'n': 16, 'o': 17, 'p': 18, 'q': 19, 'r': 20, 's': 21, 't': 22, 'u': 23, 'v': 24, 'w': 25, 'x': 26, 'y': 27, 'z': 28}
[([1, 23, 18, 18, 17, 21, 7, 20, 2], -9.539106905460358), ([1, 11, 20, 4, 7, 20, 2], -6.241151958703995), ([1, 23, 16, 4, 7, 20, 7, 20, 2], -7.6688151359558105)] False
2025-08-24 18:32:07,328 - 2025-08-24 18:31:55 - Error: 0%|          | 0/6 [00:00<?, ?it/s]

0it [00:00, ?it/s][A
0it [00:00, ?it/s]

 17%|        | 1/6 [00:00<00:02,  1.91it/s]

0it [00:00, ?it/s][A
0it [00:00, ?it/s]

 17%|        | 1/6 [00:02<00:10,  2.14s/it]
Traceback (most recent call last):
  File "/home/alfredff/Bio_Software/miniconda3/envs/luvia_py311/bin/luvia", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/home/alfredff/Toke/LUVIA/src/luvia/main.py", line 111, in main
    l.main(image_path = largs.input, rotate_image=largs.rotate_img,
  File "/home/alfredff/Toke/LUVIA/src/luvia/main.py", line 82, in main
    results = straw.infer_model(dataloader, **infer_model_args)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/alfredff/Toke/LUVIA/src/luvia/straw/straw.py", line 122, in infer_model
    output, act1, act2 = self.model.infer(image=images[i], start_token=self.vocab_dict['<START>'], end_token=self.vocab_dict['<END>'],
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/alfredff/Toke/LUVIA/src/luvia/straw/model/model.py", line 28, in infer
    infer_result = self.infer_diverse_beam(features, start_token, end_token, beam_width=beam_width,
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/alfredff/Toke/LUVIA/src/luvia/straw/model/model.py", line 47, in infer_diverse_beam
    return self.decoder.generate_diverse_beam_search(features, start_token, end_token, beam_width, num_groups,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/alfredff/Toke/LUVIA/src/luvia/straw/model/decoder.py", line 168, in generate_diverse_beam_search
    sorted_sequences = sorted(all_sequences, key=lambda x: x[1] / len(x[0]) if length_norm else x[1],
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: slice indices must be integers or None or have an __index__ method
2025-08-24 18:42:32,766 - 2025-08-24 18:42:32 - Executing: luvia main --input '/home/alfredff/Toke/Maps for Alfred/Rigensgade bw_section.jpg' --output /home/alfredff/Toke/LUVIA/test --blur_kernel 5,5 --blur_sigma 0 --block_size 15 --vthresh_C 3 --min_area 20 --max_area 2000 --min_aspect 0.1 --max_aspect 10.0 --min_vertices 6 --blur_kernel_size 5 --canny_thresh1 50 --canny_thresh2 150 --cc_min_area 20 --cc_max_area 2000 --contour_min_area 20 --contour_max_area 2000 --contour_min_vertices 5 --contour_max_vertices 0.001 --sigma 4 --separation_char 5 --hoofh_mode cca --min_area_segment 100 --dilation_kernel 90,10 --angle_tolerance 15 --filter_boxes inside_box --kernel_size 150,20 --iterations 1 --weights src/luvia/data/weights/weights2_speakcorpus_e60.pt --infer_mode diverse_beam --beam_width 3 --num_groups 3 --diversity_strength 0.5 --top_k 0 --top_p 0.9 --temperature 1.0 --k 2 --dictionary characters --character random
2025-08-24 18:43:14,527 - 2025-08-24 18:42:32 - Output: 73052 100.0
4769 100.0
21608 100.0
11903 100.0
5730 100.0
3936 100.0
5537 100.0
{'infer_mode': 'diverse_beam', 'length_norm': False, 'beam_width': 3, 'num_groups': 3, 'diversity_strength': 0.5, 'top_k': 0.0, 'top_p': 0.9, 'temperature': 1.0, 'k': 2}
{'infer_mode': 'diverse_beam', 'length_norm': False, 'beam_width': 3, 'num_groups': 3, 'diversity_strength': 0.5, 'top_k': 0.0, 'top_p': 0.9, 'temperature': 1.0, 'k': 2}
{'<PAD>': 0, '<START>': 1, '<END>': 2, 'a': 3, 'b': 4, 'c': 5, 'd': 6, 'e': 7, 'f': 8, 'g': 9, 'h': 10, 'i': 11, 'j': 12, 'k': 13, 'l': 14, 'm': 15, 'n': 16, 'o': 17, 'p': 18, 'q': 19, 'r': 20, 's': 21, 't': 22, 'u': 23, 'v': 24, 'w': 25, 'x': 26, 'y': 27, 'z': 28}
[([1, 10, 7, 20, 7, 3, 14, 2], -5.852123431861401), ([1, 20, 7, 8, 7, 20, 7, 2], -7.384103402495384), ([1, 23, 16, 4, 7, 20, 4, 7, 21, 21, 7, 21, 2], -10.46084949374199)] False
{'<PAD>': 0, '<START>': 1, '<END>': 2, 'a': 3, 'b': 4, 'c': 5, 'd': 6, 'e': 7, 'f': 8, 'g': 9, 'h': 10, 'i': 11, 'j': 12, 'k': 13, 'l': 14, 'm': 15, 'n': 16, 'o': 17, 'p': 18, 'q': 19, 'r': 20, 's': 21, 't': 22, 'u': 23, 'v': 24, 'w': 25, 'x': 26, 'y': 27, 'z': 28}
[([1, 18, 7, 20, 7, 20, 3, 16, 2], -7.621743828058243), ([1, 18, 20, 7, 16, 7, 20, 7, 2], -7.309560596942902), ([1, 18, 7, 20, 7, 16, 22, 2], -5.630565494298935)] False
{'<PAD>': 0, '<START>': 1, '<END>': 2, 'a': 3, 'b': 4, 'c': 5, 'd': 6, 'e': 7, 'f': 8, 'g': 9, 'h': 10, 'i': 11, 'j': 12, 'k': 13, 'l': 14, 'm': 15, 'n': 16, 'o': 17, 'p': 18, 'q': 19, 'r': 20, 's': 21, 't': 22, 'u': 23, 'v': 24, 'w': 25, 'x': 26, 'y': 27, 'z': 28}
[([1, 18, 7, 20, 4, 17, 11, 16, 2], -7.283686965703964), ([1, 18, 7, 20, 18, 17, 16, 2], -7.14783239364624), ([1, 18, 7, 20, 18, 7, 20, 7, 21, 21, 7, 21, 21, 2], -11.41099737584591)] False
{'<PAD>': 0, '<START>': 1, '<END>': 2, 'a': 3, 'b': 4, 'c': 5, 'd': 6, 'e': 7, 'f': 8, 'g': 9, 'h': 10, 'i': 11, 'j': 12, 'k': 13, 'l': 14, 'm': 15, 'n': 16, 'o': 17, 'p': 18, 'q': 19, 'r': 20, 's': 21, 't': 22, 'u': 23, 'v': 24, 'w': 25, 'x': 26, 'y': 27, 'z': 28}
[([1, 18, 17, 20, 7, 21, 23, 20, 7, 21, 2], -10.780696824193), ([1, 18, 17, 18, 7, 20, 3, 22, 2], -8.03265106678009), ([1, 18, 3, 20, 18, 7, 20, 7, 21, 21, 2], -9.364009499549866)] False
{'<PAD>': 0, '<START>': 1, '<END>': 2, 'a': 3, 'b': 4, 'c': 5, 'd': 6, 'e': 7, 'f': 8, 'g': 9, 'h': 10, 'i': 11, 'j': 12, 'k': 13, 'l': 14, 'm': 15, 'n': 16, 'o': 17, 'p': 18, 'q': 19, 'r': 20, 's': 21, 't': 22, 'u': 23, 'v': 24, 'w': 25, 'x': 26, 'y': 27, 'z': 28}
[([1, 18, 7, 20, 21, 7, 18, 2], -7.435382753610611), ([1, 18, 7, 20, 7, 20, 7, 21, 21, 11, 4, 4, 7, 20, 2], -12.956280052661896), ([1, 18, 7, 20, 4, 3, 16, 22, 2], -6.387213617563248)] False
{'<PAD>': 0, '<START>': 1, '<END>': 2, 'a': 3, 'b': 4, 'c': 5, 'd': 6, 'e': 7, 'f': 8, 'g': 9, 'h': 10, 'i': 11, 'j': 12, 'k': 13, 'l': 14, 'm': 15, 'n': 16, 'o': 17, 'p': 18, 'q': 19, 'r': 20, 's': 21, 't': 22, 'u': 23, 'v': 24, 'w': 25, 'x': 26, 'y': 27, 'z': 28}
[([1, 23, 21, 18, 7, 20, 2], -4.647822737693787), ([1, 23, 18, 18, 7, 20, 2], -4.571334630250931), ([1, 21, 23, 18, 18, 7, 20, 21, 7, 2], -8.428663849830627)] False
{'<PAD>': 0, '<START>': 1, '<END>': 2, 'a': 3, 'b': 4, 'c': 5, 'd': 6, 'e': 7, 'f': 8, 'g': 9, 'h': 10, 'i': 11, 'j': 12, 'k': 13, 'l': 14, 'm': 15, 'n': 16, 'o': 17, 'p': 18, 'q': 19, 'r': 20, 's': 21, 't': 22, 'u': 23, 'v': 24, 'w': 25, 'x': 26, 'y': 27, 'z': 28}
[([1, 23, 18, 18, 7, 20, 17, 15, 2], -8.735907316207886), ([1, 23, 18, 18, 23, 20, 7, 20, 2], -7.6484405398368835), ([1, 23, 18, 18, 7, 20, 2], -5.172674357891083)] False
{'<PAD>': 0, '<START>': 1, '<END>': 2, 'a': 3, 'b': 4, 'c': 5, 'd': 6, 'e': 7, 'f': 8, 'g': 9, 'h': 10, 'i': 11, 'j': 12, 'k': 13, 'l': 14, 'm': 15, 'n': 16, 'o': 17, 'p': 18, 'q': 19, 'r': 20, 's': 21, 't': 22, 'u': 23, 'v': 24, 'w': 25, 'x': 26, 'y': 27, 'z': 28}
[([1, 8, 3, 20, 15, 7, 16, 2], -8.076875060796738), ([1, 17, 4, 21, 23, 21, 7, 2], -8.087965190410614), ([1, 18, 7, 20, 7, 28, 7, 20, 2], -8.41929978132248)] False
{'infer_mode': 'diverse_beam', 'length_norm': False, 'beam_width': 3, 'num_groups': 3, 'diversity_strength': 0.5, 'top_k': 0.0, 'top_p': 0.9, 'temperature': 1.0, 'k': 2}
{'<PAD>': 0, '<START>': 1, '<END>': 2, 'a': 3, 'b': 4, 'c': 5, 'd': 6, 'e': 7, 'f': 8, 'g': 9, 'h': 10, 'i': 11, 'j': 12, 'k': 13, 'l': 14, 'm': 15, 'n': 16, 'o': 17, 'p': 18, 'q': 19, 'r': 20, 's': 21, 't': 22, 'u': 23, 'v': 24, 'w': 25, 'x': 26, 'y': 27, 'z': 28}
[([1, 18, 3, 20, 7, 2], -4.9302719831466675), ([1, 18, 7, 20, 7, 16, 7, 2], -6.5450475215911865), ([1, 18, 14, 7, 2], -4.4243247509002686)] False
{'<PAD>': 0, '<START>': 1, '<END>': 2, 'a': 3, 'b': 4, 'c': 5, 'd': 6, 'e': 7, 'f': 8, 'g': 9, 'h': 10, 'i': 11, 'j': 12, 'k': 13, 'l': 14, 'm': 15, 'n': 16, 'o': 17, 'p': 18, 'q': 19, 'r': 20, 's': 21, 't': 22, 'u': 23, 'v': 24, 'w': 25, 'x': 26, 'y': 27, 'z': 28}
[([1, 15, 7, 16, 22, 2], -3.248843014240265), ([1, 15, 7, 16, 7, 14, 2], -4.728588759899139), ([1, 23, 16, 7, 14, 7, 15, 7, 16, 22, 2], -9.724886000156403)] False
{'<PAD>': 0, '<START>': 1, '<END>': 2, 'a': 3, 'b': 4, 'c': 5, 'd': 6, 'e': 7, 'f': 8, 'g': 9, 'h': 10, 'i': 11, 'j': 12, 'k': 13, 'l': 14, 'm': 15, 'n': 16, 'o': 17, 'p': 18, 'q': 19, 'r': 20, 's': 21, 't': 22, 'u': 23, 'v': 24, 'w': 25, 'x': 26, 'y': 27, 'z': 28}
[([1, 18, 7, 20, 4, 23, 16, 3, 4, 2], -10.129938781261444), ([1, 23, 18, 4, 17, 20, 7, 20, 2], -7.266783386468887), ([1, 18, 7, 20, 4, 23, 16, 4, 7, 20, 2], -7.860788255929947)] False
{'infer_mode': 'diverse_beam', 'length_norm': False, 'beam_width': 3, 'num_groups': 3, 'diversity_strength': 0.5, 'top_k': 0.0, 'top_p': 0.9, 'temperature': 1.0, 'k': 2}
{'<PAD>': 0, '<START>': 1, '<END>': 2, 'a': 3, 'b': 4, 'c': 5, 'd': 6, 'e': 7, 'f': 8, 'g': 9, 'h': 10, 'i': 11, 'j': 12, 'k': 13, 'l': 14, 'm': 15, 'n': 16, 'o': 17, 'p': 18, 'q': 19, 'r': 20, 's': 21, 't': 22, 'u': 23, 'v': 24, 'w': 25, 'x': 26, 'y': 27, 'z': 28}
[([1, 10, 7, 20, 7, 15, 7, 16, 22, 2], -7.276776969432831), ([1, 10, 7, 7, 20, 2], -5.980063259601593), ([1, 10, 7, 3, 6, 2], -5.921759247779846)] False
{'infer_mode': 'diverse_beam', 'length_norm': False, 'beam_width': 3, 'num_groups': 3, 'diversity_strength': 0.5, 'top_k': 0.0, 'top_p': 0.9, 'temperature': 1.0, 'k': 2}
{'<PAD>': 0, '<START>': 1, '<END>': 2, 'a': 3, 'b': 4, 'c': 5, 'd': 6, 'e': 7, 'f': 8, 'g': 9, 'h': 10, 'i': 11, 'j': 12, 'k': 13, 'l': 14, 'm': 15, 'n': 16, 'o': 17, 'p': 18, 'q': 19, 'r': 20, 's': 21, 't': 22, 'u': 23, 'v': 24, 'w': 25, 'x': 26, 'y': 27, 'z': 28}
[([1, 15, 7, 20, 3, 14, 2], -6.318242728710175), ([1, 15, 17, 15, 7, 20, 7, 3, 14, 17, 2], -11.245444729924202), ([1, 23, 15, 7, 16, 7, 15, 3, 14, 3, 16, 9, 3, 22, 11, 6, 7, 2], -19.241665184497833)] False
{'infer_mode': 'diverse_beam', 'length_norm': False, 'beam_width': 3, 'num_groups': 3, 'diversity_strength': 0.5, 'top_k': 0.0, 'top_p': 0.9, 'temperature': 1.0, 'k': 2}
{'<PAD>': 0, '<START>': 1, '<END>': 2, 'a': 3, 'b': 4, 'c': 5, 'd': 6, 'e': 7, 'f': 8, 'g': 9, 'h': 10, 'i': 11, 'j': 12, 'k': 13, 'l': 14, 'm': 15, 'n': 16, 'o': 17, 'p': 18, 'q': 19, 'r': 20, 's': 21, 't': 22, 'u': 23, 'v': 24, 'w': 25, 'x': 26, 'y': 27, 'z': 28}
[([1, 5, 20, 7, 15, 7, 16, 22, 2], -8.848198510706425), ([1, 23, 16, 7, 3, 22, 2], -6.033750951290131), ([1, 5, 3, 14, 2], -4.651560336351395)] False
{'<PAD>': 0, '<START>': 1, '<END>': 2, 'a': 3, 'b': 4, 'c': 5, 'd': 6, 'e': 7, 'f': 8, 'g': 9, 'h': 10, 'i': 11, 'j': 12, 'k': 13, 'l': 14, 'm': 15, 'n': 16, 'o': 17, 'p': 18, 'q': 19, 'r': 20, 's': 21, 't': 22, 'u': 23, 'v': 24, 'w': 25, 'x': 26, 'y': 27, 'z': 28}
[([1, 20, 7, 3, 20, 6, 2], -3.481467068195343), ([1, 20, 7, 8, 7, 16, 22, 2], -5.674232840538025), ([1, 20, 7, 21, 18, 7, 20, 2], -5.6404415518045425)] False
2025-08-24 18:43:14,528 - 2025-08-24 18:42:32 - Error: 0%|          | 0/6 [00:00<?, ?it/s]

0it [00:00, ?it/s][A
0it [00:00, ?it/s]

 17%|        | 1/6 [00:00<00:02,  1.82it/s]

0it [00:00, ?it/s][A

1it [00:01,  1.19s/it][A
1it [00:01,  1.24s/it]

 33%|      | 2/6 [00:15<00:36,  9.13s/it]

0it [00:00, ?it/s][A

1it [00:00,  3.71it/s][A
1it [00:00,  3.19it/s]

 50%|     | 3/6 [00:22<00:23,  7.89s/it]

0it [00:00, ?it/s][A

1it [00:00,  5.73it/s][A
1it [00:00,  4.41it/s]

 67%|   | 4/6 [00:24<00:11,  5.65s/it]

0it [00:00, ?it/s][A

1it [00:00,  3.45it/s][A
1it [00:00,  2.85it/s]

 83%| | 5/6 [00:27<00:04,  4.67s/it]

0it [00:00, ?it/s][A

1it [00:00,  2.92it/s][A
1it [00:00,  2.52it/s]

100%|| 6/6 [00:32<00:00,  4.70s/it]
100%|| 6/6 [00:32<00:00,  5.34s/it]
2025-08-25 17:09:32,612 - 2025-08-25 17:09:32 - Executing: luvia main --input '/home/alfredff/Toke/Maps for Alfred/Rigensgade bw_section.jpg' --output /home/alfredff/Toke/LUVIA/test --blur_kernel 5,5 --blur_sigma 0 --block_size 15 --vthresh_C 3 --min_area 20 --max_area 2000 --min_aspect 0.1 --max_aspect 10.0 --min_vertices 6 --blur_kernel_size 5 --canny_thresh1 50 --canny_thresh2 150 --cc_min_area 20 --cc_max_area 2000 --contour_min_area 20 --contour_max_area 2000 --contour_min_vertices 5 --contour_max_vertices 0.001 --sigma 4 --separation_char 5 --hoofh_mode cca --min_area_segment 100 --dilation_kernel 90,10 --angle_tolerance 15 --filter_boxes inside_box --kernel_size 150,20 --iterations 1 --infer_mode diverse_beam --length_norm --beam_width 3 --num_groups 3 --diversity_strength 0.5 --top_k 0 --top_p 0.9 --temperature 1.0 --k 1 --sel_sentence quantile --quantile 5th --final_sentences 2
2025-08-25 17:11:37,277 - 2025-08-25 17:11:37 - Executing: luvia main --input '/home/alfredff/Toke/Maps for Alfred/Rigensgade bw_section.jpg' --output /home/alfredff/Toke/LUVIA/test --blur_kernel 5,5 --blur_sigma 0 --block_size 15 --vthresh_C 3 --min_area 20 --max_area 2000 --min_aspect 0.1 --max_aspect 10.0 --min_vertices 6 --blur_kernel_size 5 --canny_thresh1 50 --canny_thresh2 150 --cc_min_area 20 --cc_max_area 2000 --contour_min_area 20 --contour_max_area 2000 --contour_min_vertices 5 --contour_max_vertices 0.001 --sigma 4 --separation_char 5 --hoofh_mode cca --min_area_segment 100 --dilation_kernel 90,10 --angle_tolerance 15 --filter_boxes inside_box --kernel_size 150,20 --iterations 1 --infer_mode diverse_beam --length_norm --beam_width 3 --num_groups 3 --diversity_strength 0.5 --top_k 0 --top_p 0.9 --temperature 1.0 --k 1 --sel_sentence quantile --quantile 5th --final_sentences 2
2025-08-25 17:14:54,409 - 2025-08-25 17:14:54 - Executing: luvia main --input '/home/alfredff/Toke/Maps for Alfred/Rigensgade bw_section.jpg' --output /home/alfredff/Toke/LUVIA/test --blur_kernel 5,5 --blur_sigma 0 --block_size 15 --vthresh_C 3 --min_area 20 --max_area 2000 --min_aspect 0.1 --max_aspect 10.0 --min_vertices 6 --blur_kernel_size 5 --canny_thresh1 50 --canny_thresh2 150 --cc_min_area 20 --cc_max_area 2000 --contour_min_area 20 --contour_max_area 2000 --contour_min_vertices 5 --contour_max_vertices 0.001 --sigma 4 --separation_char 5 --hoofh_mode cca --min_area_segment 100 --dilation_kernel 90,10 --angle_tolerance 15 --filter_boxes inside_box --kernel_size 150,20 --iterations 1 --infer_mode diverse_beam --length_norm --beam_width 3 --num_groups 3 --diversity_strength 0.5 --top_k 0 --top_p 0.9 --temperature 1.0 --k 1 --sel_sentence quantile --quantile 5th --final_sentences 2
2025-08-25 17:16:59,721 - 2025-08-25 17:16:59 - Executing: 
2025-08-25 17:17:18,743 - 2025-08-25 17:17:18 - Executing: 
2025-08-25 17:17:24,435 - 2025-08-25 17:17:24 - Executing: luvia main --input '/home/alfredff/Toke/Maps for Alfred/Rigensgade bw_section.jpg' --output /home/alfredff/Toke/LUVIA/test --blur_kernel 5,5 --blur_sigma 0 --block_size 15 --vthresh_C 3 --min_area 20 --max_area 2000 --min_aspect 0.1 --max_aspect 10.0 --min_vertices 6 --blur_kernel_size 5 --canny_thresh1 50 --canny_thresh2 150 --cc_min_area 20 --cc_max_area 2000 --contour_min_area 20 --contour_max_area 2000 --contour_min_vertices 5 --contour_max_vertices 0.001 --sigma 4 --separation_char 5 --hoofh_mode cca --min_area_segment 100 --dilation_kernel 90,10 --angle_tolerance 15 --filter_boxes inside_box --kernel_size 150,20 --iterations 1 --infer_mode diverse_beam --length_norm --beam_width 3 --num_groups 3 --diversity_strength 0.5 --top_k 0 --top_p 0.9 --temperature 1.0 --k 1
2025-08-25 17:19:56,525 - 2025-08-25 17:17:24 - Error: 0%|          | 0/6 [00:00<?, ?it/s]

  0%|          | 0/1 [00:00<?, ?it/s][A

100%|| 1/1 [00:00<00:00,  2.29it/s][A
100%|| 1/1 [00:00<00:00,  2.04it/s]
`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.

 17%|        | 1/6 [00:08<00:43,  8.64s/it]

  0%|          | 0/1 [00:00<?, ?it/s][Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)


100%|| 1/1 [00:01<00:00,  1.17s/it][A
100%|| 1/1 [00:01<00:00,  1.22s/it]

 33%|      | 2/6 [01:17<02:56, 44.03s/it]

  0%|          | 0/1 [00:00<?, ?it/s][Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)


100%|| 1/1 [00:00<00:00,  1.55it/s][A
100%|| 1/1 [00:00<00:00,  1.41it/s]

 50%|     | 3/6 [01:47<01:53, 37.68s/it]

  0%|          | 0/1 [00:00<?, ?it/s][Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)


100%|| 1/1 [00:00<00:00,  2.01it/s][A
100%|| 1/1 [00:00<00:00,  1.74it/s]

 67%|   | 4/6 [01:57<00:53, 26.75s/it]

  0%|          | 0/1 [00:00<?, ?it/s][Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)


100%|| 1/1 [00:00<00:00,  2.43it/s][A
100%|| 1/1 [00:00<00:00,  2.11it/s]

 83%| | 5/6 [02:06<00:20, 20.48s/it]

  0%|          | 0/1 [00:00<?, ?it/s][Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)


100%|| 1/1 [00:00<00:00,  1.97it/s][A
100%|| 1/1 [00:00<00:00,  1.75it/s]

100%|| 6/6 [02:23<00:00, 19.01s/it]
100%|| 6/6 [02:23<00:00, 23.84s/it]
2025-08-25 17:29:16,110 - 2025-08-25 17:29:16 - Executed: luvia main --input '/home/alfredff/Toke/Maps for Alfred/Rigensgade bw_section.jpg' --output /home/alfredff/Toke/LUVIA/test --blur_kernel 5,5 --blur_sigma 0 --block_size 15 --vthresh_C 3 --min_area 20 --max_area 2000 --min_aspect 0.1 --max_aspect 10.0 --min_vertices 6 --blur_kernel_size 5 --canny_thresh1 50 --canny_thresh2 150 --cc_min_area 20 --cc_max_area 2000 --contour_min_area 20 --contour_max_area 2000 --contour_min_vertices 5 --contour_max_vertices 0.001 --sigma 4 --separation_char 5 --hoofh_mode cca --min_area_segment 100 --dilation_kernel 90,10 --angle_tolerance 15 --filter_boxes inside_box --kernel_size 150,20 --iterations 1 --infer_mode diverse_beam --length_norm --beam_width 3 --num_groups 3 --diversity_strength 0.5 --top_k 0 --top_p 0.9 --temperature 1.0 --k 1
2025-08-25 17:29:16,110 - 2025-08-25 17:29:16 - Error: 0%|          | 0/6 [00:00<?, ?it/s]

  0%|          | 0/1 [00:00<?, ?it/s][A

100%|| 1/1 [00:00<00:00,  2.42it/s][A
100%|| 1/1 [00:00<00:00,  2.19it/s]
`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.

 17%|        | 1/6 [00:09<00:46,  9.28s/it]

  0%|          | 0/1 [00:00<?, ?it/s][Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)


100%|| 1/1 [00:01<00:00,  1.18s/it][A
100%|| 1/1 [00:01<00:00,  1.22s/it]

 33%|      | 2/6 [01:26<03:17, 49.47s/it]

  0%|          | 0/1 [00:00<?, ?it/s][Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)


100%|| 1/1 [00:00<00:00,  1.87it/s][A
100%|| 1/1 [00:00<00:00,  1.71it/s]

 50%|     | 3/6 [01:59<02:05, 41.74s/it]

  0%|          | 0/1 [00:00<?, ?it/s][Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)


100%|| 1/1 [00:00<00:00,  2.25it/s][A
100%|| 1/1 [00:00<00:00,  1.99it/s]

 67%|   | 4/6 [02:09<00:58, 29.23s/it]

  0%|          | 0/1 [00:00<?, ?it/s][Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)


100%|| 1/1 [00:00<00:00,  2.30it/s][A
100%|| 1/1 [00:00<00:00,  2.02it/s]

 83%| | 5/6 [02:18<00:21, 21.99s/it]

  0%|          | 0/1 [00:00<?, ?it/s][Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)


100%|| 1/1 [00:00<00:00,  1.87it/s][A
100%|| 1/1 [00:00<00:00,  1.71it/s]

100%|| 6/6 [02:33<00:00, 19.70s/it]
100%|| 6/6 [02:33<00:00, 25.65s/it]
2025-08-25 18:43:33,112 - 2025-08-25 18:43:33 - Executed: luvia main --input '/home/alfredff/Toke/Maps for Alfred/Rigensgade bw_section.jpg' --output /home/alfredff/Toke/LUVIA/test --blur_kernel 5,5 --blur_sigma 0 --block_size 15 --vthresh_C 3 --min_area 20 --max_area 2000 --min_aspect 0.1 --max_aspect 10.0 --min_vertices 6 --blur_kernel_size 5 --canny_thresh1 50 --canny_thresh2 150 --cc_min_area 20 --cc_max_area 2000 --contour_min_area 20 --contour_max_area 2000 --contour_min_vertices 5 --contour_max_vertices 0.001 --sigma 4 --separation_char 5 --hoofh_mode cca --min_area_segment 100 --dilation_kernel 90,10 --angle_tolerance 15 --filter_boxes inside_box --kernel_size 150,20 --iterations 1 --infer_mode diverse_beam --length_norm --beam_width 3 --num_groups 3 --diversity_strength 0.5 --top_k 0 --top_p 0.9 --temperature 1.0 --k 1
2025-08-25 18:43:33,113 - 2025-08-25 18:43:33 - Error: /home/alfredff/Bio_Software/miniconda3/envs/luvia_py311/lib/python3.11/site-packages/albumentations/check_version.py:147: UserWarning: Error fetching version info <urlopen error [Errno -3] Temporary failure in name resolution>
  data = fetch_version_info()

  0%|          | 0/6 [00:00<?, ?it/s]

  0%|          | 0/1 [00:00<?, ?it/s][A

100%|| 1/1 [00:00<00:00,  2.16it/s][A
100%|| 1/1 [00:00<00:00,  1.94it/s]

  0%|          | 0/6 [00:02<?, ?it/s]
Traceback (most recent call last):
  File "/home/alfredff/Bio_Software/miniconda3/envs/luvia_py311/lib/python3.11/site-packages/urllib3/connection.py", line 198, in _new_conn
    sock = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/alfredff/Bio_Software/miniconda3/envs/luvia_py311/lib/python3.11/site-packages/urllib3/util/connection.py", line 60, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/alfredff/Bio_Software/miniconda3/envs/luvia_py311/lib/python3.11/socket.py", line 974, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
socket.gaierror: [Errno -3] Temporary failure in name resolution

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/alfredff/Bio_Software/miniconda3/envs/luvia_py311/lib/python3.11/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/home/alfredff/Bio_Software/miniconda3/envs/luvia_py311/lib/python3.11/site-packages/urllib3/connectionpool.py", line 488, in _make_request
    raise new_e
  File "/home/alfredff/Bio_Software/miniconda3/envs/luvia_py311/lib/python3.11/site-packages/urllib3/connectionpool.py", line 464, in _make_request
    self._validate_conn(conn)
  File "/home/alfredff/Bio_Software/miniconda3/envs/luvia_py311/lib/python3.11/site-packages/urllib3/connectionpool.py", line 1093, in _validate_conn
    conn.connect()
  File "/home/alfredff/Bio_Software/miniconda3/envs/luvia_py311/lib/python3.11/site-packages/urllib3/connection.py", line 753, in connect
    self.sock = sock = self._new_conn()
                       ^^^^^^^^^^^^^^^^
  File "/home/alfredff/Bio_Software/miniconda3/envs/luvia_py311/lib/python3.11/site-packages/urllib3/connection.py", line 205, in _new_conn
    raise NameResolutionError(self.host, self, e) from e
urllib3.exceptions.NameResolutionError: <urllib3.connection.HTTPSConnection object at 0x7ef8e1dd61d0>: Failed to resolve 'huggingface.co' ([Errno -3] Temporary failure in name resolution)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/alfredff/Bio_Software/miniconda3/envs/luvia_py311/lib/python3.11/site-packages/requests/adapters.py", line 667, in send
    resp = conn.urlopen(
           ^^^^^^^^^^^^^
  File "/home/alfredff/Bio_Software/miniconda3/envs/luvia_py311/lib/python3.11/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File "/home/alfredff/Bio_Software/miniconda3/envs/luvia_py311/lib/python3.11/site-packages/urllib3/util/retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /api/models/gpt2/tree/main/additional_chat_templates?recursive=False&expand=False (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x7ef8e1dd61d0>: Failed to resolve 'huggingface.co' ([Errno -3] Temporary failure in name resolution)"))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/alfredff/Bio_Software/miniconda3/envs/luvia_py311/bin/luvia", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/home/alfredff/Toke/LUVIA/src/luvia/main.py", line 135, in main
    l.main(image_path = largs.input, rotate_image=largs.rotate_img,
  File "/home/alfredff/Toke/LUVIA/src/luvia/main.py", line 106, in main
    tongue = Tongue(match_mode=dictionary, character=character)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/alfredff/Toke/LUVIA/src/luvia/tongue/tongue.py", line 31, in __init__
    self.tokenizer = GPT2TokenizerFast.from_pretrained("gpt2")
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/alfredff/Bio_Software/miniconda3/envs/luvia_py311/lib/python3.11/site-packages/transformers/tokenization_utils_base.py", line 1956, in from_pretrained
    for template in list_repo_templates(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/home/alfredff/Bio_Software/miniconda3/envs/luvia_py311/lib/python3.11/site-packages/transformers/utils/hub.py", line 167, in list_repo_templates
    return [
           ^
  File "/home/alfredff/Bio_Software/miniconda3/envs/luvia_py311/lib/python3.11/site-packages/transformers/utils/hub.py", line 167, in <listcomp>
    return [
           ^
  File "/home/alfredff/Bio_Software/miniconda3/envs/luvia_py311/lib/python3.11/site-packages/huggingface_hub/hf_api.py", line 3171, in list_repo_tree
    for path_info in paginate(path=tree_url, headers=headers, params={"recursive": recursive, "expand": expand}):
  File "/home/alfredff/Bio_Software/miniconda3/envs/luvia_py311/lib/python3.11/site-packages/huggingface_hub/utils/_pagination.py", line 36, in paginate
    r = session.get(path, params=params, headers=headers)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/alfredff/Bio_Software/miniconda3/envs/luvia_py311/lib/python3.11/site-packages/requests/sessions.py", line 602, in get
    return self.request("GET", url, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/alfredff/Bio_Software/miniconda3/envs/luvia_py311/lib/python3.11/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/alfredff/Bio_Software/miniconda3/envs/luvia_py311/lib/python3.11/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/alfredff/Bio_Software/miniconda3/envs/luvia_py311/lib/python3.11/site-packages/huggingface_hub/utils/_http.py", line 96, in send
    return super().send(request, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/alfredff/Bio_Software/miniconda3/envs/luvia_py311/lib/python3.11/site-packages/requests/adapters.py", line 700, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /api/models/gpt2/tree/main/additional_chat_templates?recursive=False&expand=False (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x7ef8e1dd61d0>: Failed to resolve \'huggingface.co\' ([Errno -3] Temporary failure in name resolution)"))'), '(Request ID: f8624387-14d2-4e85-8f0e-1f2334dd236f)')
2025-08-25 18:46:53,436 - 2025-08-25 18:46:53 - Executed: luvia main --input '/home/alfredff/Toke/Maps for Alfred/Rigensgade bw_section.jpg' --output /home/alfredff/Toke/LUVIA/test --blur_kernel 5,5 --blur_sigma 0 --block_size 15 --vthresh_C 3 --min_area 20 --max_area 2000 --min_aspect 0.1 --max_aspect 10.0 --min_vertices 6 --blur_kernel_size 5 --canny_thresh1 50 --canny_thresh2 150 --cc_min_area 20 --cc_max_area 2000 --contour_min_area 20 --contour_max_area 2000 --contour_min_vertices 5 --contour_max_vertices 0.001 --sigma 4 --separation_char 5 --hoofh_mode cca --min_area_segment 100 --dilation_kernel 90,10 --angle_tolerance 15 --filter_boxes inside_box --kernel_size 150,20 --iterations 1 --infer_mode diverse_beam --length_norm --beam_width 3 --num_groups 3 --diversity_strength 0.5 --top_k 0 --top_p 0.9 --temperature 1.0 --k 1
2025-08-25 18:46:53,437 - 2025-08-25 18:46:53 - Error: 0%|          | 0/6 [00:00<?, ?it/s]

  0%|          | 0/1 [00:00<?, ?it/s][A

100%|| 1/1 [00:00<00:00,  3.47it/s][A
100%|| 1/1 [00:00<00:00,  3.00it/s]
`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.

 17%|        | 1/6 [00:10<00:54, 10.88s/it]

  0%|          | 0/1 [00:00<?, ?it/s][Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)


100%|| 1/1 [00:01<00:00,  1.22s/it][A
100%|| 1/1 [00:01<00:00,  1.28s/it]

 33%|      | 2/6 [01:04<02:23, 35.86s/it]

  0%|          | 0/1 [00:00<?, ?it/s][Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)


100%|| 1/1 [00:00<00:00,  1.50it/s][A
100%|| 1/1 [00:00<00:00,  1.37it/s]

 50%|     | 3/6 [01:32<01:37, 32.61s/it]

  0%|          | 0/1 [00:00<?, ?it/s][Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)


100%|| 1/1 [00:00<00:00,  2.46it/s][A
100%|| 1/1 [00:00<00:00,  2.14it/s]

 67%|   | 4/6 [01:43<00:48, 24.09s/it]

  0%|          | 0/1 [00:00<?, ?it/s][Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)


100%|| 1/1 [00:00<00:00,  2.24it/s][A
100%|| 1/1 [00:00<00:00,  1.99it/s]

 83%| | 5/6 [01:54<00:19, 19.05s/it]

  0%|          | 0/1 [00:00<?, ?it/s][Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)


100%|| 1/1 [00:00<00:00,  1.94it/s][A
100%|| 1/1 [00:00<00:00,  1.77it/s]

100%|| 6/6 [02:12<00:00, 18.77s/it]
100%|| 6/6 [02:12<00:00, 22.06s/it]
2025-08-25 19:21:29,322 - 2025-08-25 19:21:29 - Executed: luvia main --input '/home/alfredff/Toke/Maps for Alfred/Rigensgade bw_section2.jpg' --output /home/alfredff/Toke/LUVIA/test --blur_kernel 5,5 --blur_sigma 0 --block_size 15 --vthresh_C 3 --min_area 20 --max_area 2000 --min_aspect 0.1 --max_aspect 10.0 --min_vertices 6 --blur_kernel_size 5 --canny_thresh1 50 --canny_thresh2 150 --cc_min_area 20 --cc_max_area 2000 --contour_min_area 20 --contour_max_area 2000 --contour_min_vertices 5 --contour_max_vertices 0.001 --sigma 4 --separation_char 5 --hoofh_mode cca --min_area_segment 100 --dilation_kernel 90,10 --angle_tolerance 15 --filter_boxes inside_box --kernel_size 150,20 --iterations 1 --infer_mode diverse_beam --length_norm --beam_width 3 --num_groups 3 --diversity_strength 0.5 --top_k 0 --top_p 0.9 --temperature 1.0 --k 1
2025-08-25 19:21:29,322 - 2025-08-25 19:21:29 - Error: 0%|          | 0/13 [00:00<?, ?it/s]

  0%|          | 0/1 [00:00<?, ?it/s][A

100%|| 1/1 [00:00<00:00,  2.19it/s][A
100%|| 1/1 [00:00<00:00,  2.00it/s]
`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.

  8%|         | 1/13 [00:10<02:04, 10.40s/it]

  0%|          | 0/1 [00:00<?, ?it/s][Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)


100%|| 1/1 [00:00<00:00,  3.27it/s][A
100%|| 1/1 [00:00<00:00,  2.79it/s]

 15%|        | 2/13 [00:21<02:00, 10.94s/it]

  0%|          | 0/1 [00:00<?, ?it/s][Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)


100%|| 1/1 [00:00<00:00,  3.42it/s][A
100%|| 1/1 [00:00<00:00,  2.92it/s]

 23%|       | 3/13 [00:32<01:50, 11.01s/it]

  0%|          | 0/1 [00:00<?, ?it/s][Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)


100%|| 1/1 [00:00<00:00,  2.51it/s][A
100%|| 1/1 [00:00<00:00,  2.22it/s]

 31%|       | 4/13 [00:44<01:39, 11.09s/it]

  0%|          | 0/1 [00:00<?, ?it/s][Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)


100%|| 1/1 [00:00<00:00,  2.50it/s][A
100%|| 1/1 [00:00<00:00,  2.19it/s]

 38%|      | 5/13 [00:54<01:27, 10.92s/it]

  0%|          | 0/1 [00:00<?, ?it/s][Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)


100%|| 1/1 [00:00<00:00,  3.26it/s][A
100%|| 1/1 [00:00<00:00,  2.73it/s]

 46%|     | 6/13 [01:04<01:14, 10.66s/it]

  0%|          | 0/1 [00:00<?, ?it/s][Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)


100%|| 1/1 [00:00<00:00,  2.32it/s][A
100%|| 1/1 [00:00<00:00,  2.04it/s]

 54%|    | 7/13 [01:16<01:06, 11.08s/it]

  0%|          | 0/1 [00:00<?, ?it/s][Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)


100%|| 1/1 [00:00<00:00,  2.58it/s][A
100%|| 1/1 [00:00<00:00,  2.27it/s]

 62%|   | 8/13 [01:27<00:54, 10.90s/it]

  0%|          | 0/1 [00:00<?, ?it/s][Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)


100%|| 1/1 [00:00<00:00,  2.50it/s][A
100%|| 1/1 [00:00<00:00,  2.17it/s]

 69%|   | 9/13 [01:39<00:45, 11.35s/it]

  0%|          | 0/1 [00:00<?, ?it/s][Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)


100%|| 1/1 [00:00<00:00,  2.29it/s][A
100%|| 1/1 [00:00<00:00,  2.00it/s]

 77%|  | 10/13 [01:51<00:34, 11.36s/it]

  0%|          | 0/1 [00:00<?, ?it/s][Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)


100%|| 1/1 [00:00<00:00,  1.45it/s][A
100%|| 1/1 [00:00<00:00,  1.32it/s]

 85%| | 11/13 [02:17<00:32, 16.08s/it]

  0%|          | 0/1 [00:00<?, ?it/s][Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)


100%|| 1/1 [00:00<00:00,  2.54it/s][A
100%|| 1/1 [00:00<00:00,  2.23it/s]

 92%|| 12/13 [02:28<00:14, 14.53s/it]

  0%|          | 0/1 [00:00<?, ?it/s][Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)


100%|| 1/1 [00:01<00:00,  1.37s/it][A
100%|| 1/1 [00:01<00:00,  1.42s/it]

100%|| 13/13 [03:39<00:00, 31.49s/it]
100%|| 13/13 [03:39<00:00, 16.87s/it]
2025-08-25 19:31:47,756 - 2025-08-25 19:31:47 - Executed: luvia main --input '/home/alfredff/Toke/Maps for Alfred/Rigensgade bw_section2.jpg' --output /home/alfredff/Toke/LUVIA/test --blur_kernel 5,5 --blur_sigma 0 --block_size 15 --vthresh_C 3 --min_area 20 --max_area 2000 --min_aspect 0.1 --max_aspect 10.0 --min_vertices 6 --blur_kernel_size 5 --canny_thresh1 50 --canny_thresh2 150 --cc_min_area 20 --cc_max_area 2000 --contour_min_area 20 --contour_max_area 2000 --contour_min_vertices 5 --contour_max_vertices 0.001 --sigma 4 --separation_char 5 --hoofh_mode cca --min_area_segment 100 --dilation_kernel 90,20 --angle_tolerance 15 --filter_boxes inside_box --kernel_size 150,20 --iterations 1 --infer_mode diverse_beam --length_norm --beam_width 3 --num_groups 3 --diversity_strength 0.5 --top_k 0 --top_p 0.9 --temperature 1.0 --k 1
2025-08-25 19:31:47,756 - 2025-08-25 19:31:47 - Error: 0%|          | 0/11 [00:00<?, ?it/s]

  0%|          | 0/1 [00:00<?, ?it/s][A

100%|| 1/1 [00:00<00:00,  2.71it/s][A
100%|| 1/1 [00:00<00:00,  2.35it/s]
`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.

  9%|         | 1/11 [00:10<01:43, 10.35s/it]

  0%|          | 0/1 [00:00<?, ?it/s][Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)


100%|| 1/1 [00:00<00:00,  2.62it/s][A
100%|| 1/1 [00:00<00:00,  2.32it/s]

 18%|        | 2/11 [00:21<01:37, 10.88s/it]

  0%|          | 0/1 [00:00<?, ?it/s][Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)


100%|| 1/1 [00:00<00:00,  2.19it/s][A
100%|| 1/1 [00:00<00:00,  1.91it/s]

 27%|       | 3/11 [00:34<01:32, 11.58s/it]

  0%|          | 0/1 [00:00<?, ?it/s][Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)


100%|| 1/1 [00:00<00:00,  2.64it/s][A
100%|| 1/1 [00:00<00:00,  2.33it/s]

 36%|      | 4/11 [00:44<01:18, 11.21s/it]

  0%|          | 0/1 [00:00<?, ?it/s][Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)


100%|| 1/1 [00:00<00:00,  2.46it/s][A
100%|| 1/1 [00:00<00:00,  2.13it/s]

 45%|     | 5/11 [00:55<01:06, 11.15s/it]

  0%|          | 0/1 [00:00<?, ?it/s][Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)


100%|| 1/1 [00:00<00:00,  2.54it/s][A
100%|| 1/1 [00:00<00:00,  2.21it/s]

 55%|    | 6/11 [01:06<00:55, 11.08s/it]

  0%|          | 0/1 [00:00<?, ?it/s][Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)


100%|| 1/1 [00:00<00:00,  2.55it/s][A
100%|| 1/1 [00:00<00:00,  2.24it/s]

 64%|   | 7/11 [01:17<00:44, 11.15s/it]

  0%|          | 0/1 [00:00<?, ?it/s][Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)


100%|| 1/1 [00:00<00:00,  2.26it/s][A
100%|| 1/1 [00:00<00:00,  1.94it/s]

 73%|  | 8/11 [01:30<00:34, 11.50s/it]

  0%|          | 0/1 [00:00<?, ?it/s][Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)


100%|| 1/1 [00:00<00:00,  1.60it/s][A
100%|| 1/1 [00:00<00:00,  1.45it/s]

 82%| | 9/11 [02:21<00:47, 23.95s/it]

  0%|          | 0/1 [00:00<?, ?it/s][Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)


100%|| 1/1 [00:00<00:00,  2.52it/s][A
100%|| 1/1 [00:00<00:00,  2.22it/s]

 91%| | 10/11 [02:34<00:20, 20.59s/it]

  0%|          | 0/1 [00:00<?, ?it/s][Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)


100%|| 1/1 [00:01<00:00,  1.37s/it][A
100%|| 1/1 [00:01<00:00,  1.43s/it]

100%|| 11/11 [03:53<00:00, 38.45s/it]
100%|| 11/11 [03:53<00:00, 21.23s/it]
